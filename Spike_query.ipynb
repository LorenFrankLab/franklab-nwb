{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pynwb\n",
    "import numpy as np\n",
    "\n",
    "# pip install python-intervals, *NOT* pip install intervals\n",
    "import intervals as iv\n",
    "import query_helpers as qu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams.update({'lines.solid_capstyle': 'butt'})\n",
    "mdates.rcParams.update({'date.autoformatter.microsecond': '%H:%M:%S.%f'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animday = 'Bon04'\n",
    "nwb_filename = './' + animday + '_test.nwb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read NWB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading file: %s' % nwb_filename)\n",
    "io = pynwb.NWBHDF5IO(nwb_filename, mode='r')\n",
    "nwbf = io.read()\n",
    "\n",
    "posix_offset = nwbf.session_start_time.timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect spike times and observation intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select cluster \n",
    "# TODO select cluster by metadata\n",
    "cluster_id = 30\n",
    "\n",
    "# Get cluster name\n",
    "clname_idx = nwbf.units.colnames.index('cluster_name')\n",
    "cluster_name = animday + ' ' + nwbf.units.columns[clname_idx][cluster_id]\n",
    "print('Cluster name = ' + cluster_name)\n",
    "\n",
    "# Get spike times\n",
    "spikes_t = nwbf.units['spike_times'][cluster_id]\n",
    "print('# of spikes = %d' % spikes_t.size)\n",
    "print('Time of 1st/last spike (s): %0.4f / %0.4f \\n' % (spikes_t[0], spikes_t[-1]))\n",
    "\n",
    "# Get spike observation intervals\n",
    "obs_IntervalSeries = nwbf.units['obs_intervals'][cluster_id] # returns IntervalSeries\n",
    "obs_intervals = qu.intervals_from_array(obs_IntervalSeries)\n",
    "\n",
    "print('# of intervals = %d' % len(obs_intervals))\n",
    "print('Spike Observation Intervals (s): ')\n",
    "print(obs_intervals)\n",
    "print()\n",
    "\n",
    "assert qu.times_in_intervals(spikes_t, obs_intervals), 'Spike times found outside of observation intervals'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some sample Time Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas uses nanoseconds (covers range to 2262 AD), but Python datetimes are in microseconds,\n",
    "# which is all we need, precision-wise. Hmmm...\n",
    "\n",
    "# def timestamps_to_datetime64(timestamps):\n",
    "#     '''Convert POSIX timestamps (in fractional seconds), to numpy.datetime64[ns]'''\n",
    "#     return(np.array(int(timestamps*1e9),'datetime64[ns]'))\n",
    "\n",
    "# def h5_timestamps_to_datetime64(timestamps_h5):\n",
    "#     '''Convert POSIX timestamps (in fractional seconds), to numpy.datetime64[ns]'''\n",
    "#     return(timestamps_to_datetime64(np.array(timestamps_h5)))\n",
    "    \n",
    "# Time queries\n",
    "tqs = []\n",
    "# (query, short_label, long_label, mockup answers)\n",
    "# Get spikes from epoch 1\n",
    "tqs.append((obs_intervals[0], 'A', 'Full epoch'))\n",
    "# Get spikes from all sleep epochs\n",
    "tqs.append((obs_intervals[0] | obs_intervals[2] | obs_intervals[4] | obs_intervals[6], 'B', 'Multiple epochs'))\n",
    "# Get spikes from valid interval with no spiking\n",
    "tqs.append((iv.closed(5900+posix_offset, 6200+posix_offset), 'C', 'Full overlap, no spikes'))\n",
    "# partial overlap between query and obs_int\n",
    "tqs.append((iv.closed(6600+posix_offset, 7050+posix_offset), 'D', 'Partial overlap'))\n",
    "# non-overlap between query and obs_int\n",
    "tqs.append((iv.closed(9500+posix_offset, 9900+posix_offset), 'E', 'No overlap'))\n",
    "\n",
    "\n",
    "# TODO: harmonize timestamps across speed (POSIX time?) and spikes/obs_ints. During import.\n",
    "speed = nwbf.modules['Behavior']['Speed']['Speed d4 e4']\n",
    "speed_ts = speed.timestamps.value # convert from HDF5 dataset\n",
    "# speed_ts = h5_timestamps_to_datetime64(speed.timestamps) #np.array(speed.timestamps) # convert from HDF5 dataset\n",
    "speed_data = np.array(speed.data)\n",
    "\n",
    "speed_threshold_fn = lambda x: x > 0.01 # m/s\n",
    "speed_gt_intervals = qu.intervals_from_continuous(speed_data, speed_ts, speed_threshold_fn)\n",
    "speed_gt_ep3_intervals = speed_gt_intervals & obs_intervals[2] # limit to run epochs\n",
    "\n",
    "tqs.append((speed_gt_intervals, 'F', 'Complex behavioral query'))\n",
    "\n",
    "# calculate responses\n",
    "rs = []\n",
    "for tq in tqs:\n",
    "    tq_intervals = tq[0]\n",
    "    r_intervals = tq_intervals & obs_intervals # intersection operator!\n",
    "#     print(iv.to_string(r_intervals))\n",
    "    r_spikes = qu.times_in_intervals(spikes_t,r_intervals)\n",
    "    print(len(r_spikes))\n",
    "    rs.append((r_intervals, r_spikes))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spiking and some sample Time Queries & Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(1, figsize=(15,6))\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "labels = []\n",
    "labels.append((1,'Acquired Spiking Data'))\n",
    "\n",
    "ypos = 1\n",
    "\n",
    "int_h, times_h = qu.plot_pointprocess(obs_intervals, spikes_t, axis=ax1)\n",
    "\n",
    "y_offset = -5\n",
    "spacing = 6\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "plots_h = []\n",
    "for i, tq in enumerate(tqs):\n",
    "    tq_intervals = qu.array_from_intervals(tq[0]).T\n",
    "    ypos = y_offset-i*spacing\n",
    "    labels.append((ypos, '[ %s ]  %s' % (tq[1], tq[2])))\n",
    "    line_h = ax1.plot(tq_intervals,np.full(tq_intervals.shape, ypos), \n",
    "                        color=cmap(i), linewidth=5, marker='')\n",
    "    ax1.vlines(tq_intervals, ypos, -1, color=cmap(i), linestyle='--', alpha=0.2)\n",
    "    plots_h.append(line_h[0])\n",
    "    \n",
    "    # plot query response\n",
    "    r_intervals = rs[i][0]\n",
    "    r_spikes = np.array(rs[i][1])\n",
    "\n",
    "    int_h, times_h = qu.plot_pointprocess(r_intervals, r_spikes, ypos=ypos-3, axis=ax1)\n",
    "\n",
    "ax1.set_ylim([ypos-spacing,2*spacing])\n",
    "ax1.set_yticks([l[0] for l in labels])\n",
    "ax1.set_yticklabels([l[1] for l in labels])\n",
    "\n",
    "xtick_locator = mticker.AutoLocator()\n",
    "xtick_formatter = mticker.FuncFormatter(qu.fmt_truncate_posix)\n",
    "\n",
    "ax1.xaxis.set_major_locator(xtick_locator)\n",
    "ax1.xaxis.set_major_formatter(xtick_formatter)\n",
    "\n",
    "ax1.set_xlabel('Time (s)')\n",
    "\n",
    "#ax1.set_xlim([x+1136e6 for x in [151000, 153000]])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig1.savefig('./spike_timequeries.png', dpi=200)\n",
    "\n",
    "# ax1.set_xlim((4000,4100))\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute average firing rate across intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_firing_rate(spikes_t, obs_intervals):\n",
    "    assert qu.times_in_intervals(spikes_t, obs_intervals), 'Spike times found outside of observation intervals'\n",
    "    obs_intervals = qu.array_from_intervals(obs_intervals)\n",
    "    return spikes_t.size / np.diff(obs_intervals, axis=1).sum()\n",
    "\n",
    "fr_mean_Hz = mean_firing_rate(spikes_t, obs_intervals)\n",
    "print('Mean firing rate of cluster %s: %0.3f Hz' % (cluster_name, fr_mean_Hz) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

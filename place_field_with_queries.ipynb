{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# General\n",
    "import pynwb\n",
    "import numpy as np\n",
    "\n",
    "# Local\n",
    "from nwb_query import ContinuousData, PointData, EventData, TimeIntervals, plot_PointData_multiple\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams.update({'lines.solid_capstyle': 'butt'})\n",
    "mdates.rcParams.update({'date.autoformatter.microsecond': '%H:%M:%S.%f'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "- ContinuousData accessors (based on column names? require column names?)\n",
    "- Make ContinuousData and PointProcess iterable by interval (return single interval and its data)\n",
    "- Convenience functions: obs_durations (diff of obs_intervals)\n",
    "- write occupancy function\n",
    "- query spiking by epoch before doing behavior selection (requires adding epochs to NWBfile)\n",
    "    - requires extracting epoch information from nspike\n",
    "- behavior (position/speed) indexed by time, and not by epoch name\n",
    "    - requires concatenating behav on import\n",
    "- ? Subclass PointProcess for spiking data (include other columns: clustering metadata, e.g.)\n",
    "- ? Subclass ContinuousData for Behavioral data (include SI units?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what data to analyze\n",
    "d = {}\n",
    "d['anim'] = 'Bon'\n",
    "d['day'] = 4 # 1-indexed\n",
    "\n",
    "d['epoch'] = 4 # 1-indexed\n",
    "d['cluster_id'] = 30\n",
    "\n",
    "# analysis configuration\n",
    "c = {}\n",
    "c['speed_threshold'] = 0.05 # m/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read NWB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animday = '{}{:02d}'.format(d['anim'], d['day'])\n",
    "nwb_filename = './' + animday + '_test.nwb'\n",
    "\n",
    "print('Loading file: %s' % nwb_filename)\n",
    "io = pynwb.NWBHDF5IO(nwb_filename, mode='r')\n",
    "nwbf = io.read()\n",
    " \n",
    "sst = nwbf.session_start_time.timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Query: speed of a given animal, day, and epoch\n",
    "#### NWBFile (one animal), day, epoch --> ContinuousData (speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_module_name = 'Speed d{:d} e{:d}'.format(d['day'], d['epoch']) # HACKY--we should query on epoch directly\n",
    "speed_h5py = nwbf.modules['Behavior']['Speed'][speed_module_name]\n",
    "speed = ContinuousData(samples=speed_h5py.data[()], sample_times=speed_h5py.timestamps[()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Query: position of a given animal, day, and epoch\n",
    "#### NWBFile (one animal), day, epoch --> ContinuousData (position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_module_name = 'Position d{:d} e{:d}'.format(d['day'], d['epoch']) # HACKY--we should query on epoch directly\n",
    "position_h5py = nwbf.modules['Behavior']['Position'][position_module_name]\n",
    "position_data = np.array(position_h5py.data[()], dtype=[('x','f8'),('y', 'f8')])\n",
    "position = ContinuousData(position_data, position_h5py.timestamps[()])\n",
    "\n",
    "print('*** All position records for epoch ***')\n",
    "print('# of measurements = %d' % position.samples.shape[0])\n",
    "print('# of intervals = %d' % len(position.obs_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(position.obs_intervals.durations()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Query: spiking of a given animal and cluster\n",
    "#### NWBFile (one animal), cluster --> PointData (spiking)\n",
    "\n",
    "### Time Query: Find spiking within an epoch\n",
    "#### PointData (spiking), TimeInterval (epoch) --> PointData (spiking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Query: get spiking for requested cluster\n",
    "spikes_t = nwbf.units['spike_times'][d['cluster_id']]\n",
    "obs_intervals = TimeIntervals(nwbf.units['obs_intervals'][d['cluster_id']])\n",
    "spiking_all = PointData(point_times=spikes_t, obs_intervals=obs_intervals)\n",
    "\n",
    "# Time_query on epoch:\n",
    "# TODO: we need to correctly store Epochs in nwb file, rather than use cluster intervals\n",
    "epoch_time_query = spiking_all.obs_intervals[d['epoch']-1] \n",
    "spiking = spiking_all.time_query(epoch_time_query)\n",
    "\n",
    "\n",
    "print('*** Spiking for cluster %s ***' % d['cluster_id'])\n",
    "print('# of spikes = %d' % spiking_all.point_times.shape[0])\n",
    "print('# of intervals = %d' % len(spiking_all.obs_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(spiking_all.obs_intervals.durations()))\n",
    "\n",
    "print('')\n",
    "print('*** Spiking for cluster %s during epoch %d ***' % (d['cluster_id'], d['epoch']))\n",
    "print('# of spikes = %d' % spiking.point_times.shape[0])\n",
    "print('# of intervals = %d' % len(spiking.obs_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(spiking.obs_intervals.durations()))\n",
    "\n",
    "\n",
    "# Plot spiking\n",
    "spikeplots = [(spiking_all, 'All spiking'),\n",
    "              (spiking, 'Spikes in\\nEpoch %s' % d['epoch'])]\n",
    "\n",
    "fig1 = plt.figure(1, figsize=(15,3))\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "plot_PointData_multiple(spikeplots, axis=ax1)\n",
    "\n",
    "fig2 = plt.figure(2, figsize=(15,2))\n",
    "ax2 = fig2.add_subplot(1,1,1)\n",
    "plot_PointData_multiple([spikeplots[1]], axis=ax2)\n",
    "ax2.set_title(\"Zooming in...\")\n",
    "\n",
    "pass # suppress output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Find time intervals where speed > threshold\n",
    "#### ContinuousData (speed), lambda function --> EventData (time periods where animal speed > threshold)\n",
    "This is an _analysis_, not a query, because we are not simply selecting a subset of a given datatype. i.e. We are not asking for a subset of the speed data, but rather for the intervals where it fulfills a lambda function. The lambda function could have been something different, like \"find the times of all upward threshold crossings, and then pad this by 5 seconds on either side.\". Regardless of how simple or complex the lambda function is, we consider this to be an analysis. Using the output of this to select a subset of the spiking data, however, is a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_threshold_fn = lambda x: x > c['speed_threshold']\n",
    "speed_events = speed.filter_intervals(speed_threshold_fn)\n",
    "\n",
    "print('*** Times where speed > threshold ***')\n",
    "print('# of events = %d' % len(speed_events.event_intervals))\n",
    "print('duration of events = %0.2f s' % np.sum(speed_events.durations()))\n",
    "print('# of observation intervals = %d' % len(speed_events.obs_intervals))\n",
    "print('duration of observation intervals = %0.2f s' % np.sum(speed_events.obs_durations()))\n",
    "\n",
    "# Plot continuous speed\n",
    "\n",
    "# Plot speed events\n",
    "fig1 = plt.figure(1, figsize=(15,1.5))\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "plot_EventData(speed_events, axis=ax1, ypos=1)\n",
    "ax1.set_yticks([1])\n",
    "ax1.set_yticklabels(['Run events (speed>threshold)']) # eventually use metadata from PointData object\n",
    "ax1.set_xlim(xl)\n",
    "pass # suppress output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: spiking during time intervals where speed > threshold\n",
    "#### PointData (spiking), EventData (bouts where speed > threshold) --> PointData (spiking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiking_run = spiking.time_query(speed_events)  # Use the built-in time query method on PointProcess\n",
    "\n",
    "print('*** Spiking where speed > threshold ***')\n",
    "print('# of spikes = %d' % len(spiking_run.point_times))\n",
    "print('# of intervals = %d' % len(spiking_run.obs_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(spiking_run.obs_intervals.durations()))\n",
    "print()\n",
    "\n",
    "# Plot spiking\n",
    "fig1 = plt.figure(1, figsize=(15,1.5))\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "plot_PointData(spiking_run, axis=ax1, ypos=1)\n",
    "ax1.set_yticks([1])\n",
    "ax1.set_yticklabels(['Spiking during run']) # eventually use metadata from PointData object\n",
    "ax1.set_xlim(xl)\n",
    "pass # suppress output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Mark animal position at the time of each spike\n",
    "#### PointData (spiking), ContinuousData (position [m x 2]) --> PointData with marks (spike times with associated positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiking_run_mark_pos = spiking_run.mark_with_ContinuousData(position)\n",
    "\n",
    "print('*** Spiking where speed > threshold, marked with position ***')\n",
    "print('# of marked spikes = %d' % len(spiking_run_mark_pos.point_times))\n",
    "print('# of intervals = %d' % len(spiking_run_mark_pos.obs_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(spiking_run_mark_pos.obs_intervals.durations()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: Get animal locations during running events\n",
    "#### ContinuousData (position [m x 2]), EventData (bouts where speed > threshold) --> ContinuousData (position [m_new x 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_run = position.time_query(speed_events)\n",
    "\n",
    "print('*** Position where speed > threshold ***')\n",
    "print('# of samples = %d' % position_run.samples.shape[0])\n",
    "print('# of intervals = %d' % len(position_run.obs_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(position_run.obs_intervals.durations()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spikes by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(1, figsize=(15,15))\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "ax1.axis('equal')\n",
    "\n",
    "# Line showing the animal's movement during the entire epoch\n",
    "plt.plot(position.samples[:,0], position.samples[:,1], marker='', color='gray', label='Rat location', zorder=1)\n",
    "\n",
    "# Lines showing animal movement during each interval where it was running\n",
    "run_label = 'Rat location during movement'\n",
    "for ivl in position_run.obs_intervals:\n",
    "    ivl_data = position.time_query(TimeIntervals(ivl)).samples  # x,y position at each timestep \n",
    "    plt.plot(ivl_data[:,0], ivl_data[:,1], marker='', color='red', label=run_label, zorder=2)\n",
    "    run_label = '_' # omit later lines from legend\n",
    "\n",
    "# Markers for locations where unit spiked during animal running\n",
    "plt.scatter(spiking_run_mark_pos.marks[:, 0], spiking_run_mark_pos.marks[:, 1], marker='D', s=50, label='Location at spike times during movement', zorder=3)\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('X position (m)')\n",
    "ax1.set_ylabel('Y position (m)')\n",
    "ax1.set_title('Spike-position map for {} d{} e{} c{}, speed > {:0.1f} cm/s'.format(d['anim'], d['day'], d['epoch'], d['cluster_id'], (c['speed_threshold'] * 100)))\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

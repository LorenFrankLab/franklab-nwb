{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# General\n",
    "import pynwb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Local\n",
    "from nwb_query import TimeIntervals as TI\n",
    "from nwb_query import ContinuousData, PointData, EventData, TimeIntervals, plot_PointData_multiple, plot_ContinuousData, plot_EventData\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams.update({'lines.solid_capstyle': 'butt'})\n",
    "mdates.rcParams.update({'date.autoformatter.microsecond': '%H:%M:%S.%f'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "Next up:\n",
    "- ContinuousData using pandas\n",
    "    - require column names (derive them from NWB, or schema docs!, if possible)\n",
    "\n",
    "Prettify notebook:\n",
    "  - Make plots to capture TimeQuery (original data, TimeIntervals, result)\n",
    "  - Add valid_intervals to legends of plots\n",
    "  - Add `__repr__` methods for classes and get rid of multiline print statements\n",
    "\n",
    "Plumbing:\n",
    "- Make ContinuousData and PointProcess iterable by interval (return single interval and its data)\n",
    "    -add tags as labels to plots\n",
    "- use pynwb.TimeIntervals (exercise using pynwb datatypes)\n",
    "- add valid_intervals to pynwb.TimeSeries\n",
    "- use pynwb.TimeSeries as base class for ContinuousData, PointData, EventData\n",
    "- ? Subclass PointProcess for spiking data (include other columns: clustering metadata, e.g.)\n",
    "- ? Subclass ContinuousData for Behavioral data (include SI units, samplerate?)\n",
    "- Investigate xarray for ContinuousData, etc.\n",
    "\n",
    "Usage:\n",
    "- query spiking b\n",
    "y epoch before doing behavior selection\n",
    "- behavior (position/speed) should be a time_query (using epoch tq), and not epoch name\n",
    "    - requires concatenating behav on import\n",
    "\n",
    "Analysis:\n",
    "- write occupancy function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what data to analyze\n",
    "d = {}\n",
    "d['anim'] = 'Bon'\n",
    "d['day'] = 4 # 1-indexed\n",
    "\n",
    "d['epoch'] = 4 # 1-indexed\n",
    "d['cluster_id'] = 30\n",
    "\n",
    "# analysis configuration\n",
    "c = {}\n",
    "c['speed_threshold'] = 0.05 # m/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read NWB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animday = '{}{:02d}'.format(d['anim'], d['day'])\n",
    "nwb_filename = './' + animday + '_test.nwb'\n",
    "\n",
    "print('Loading file: %s' % nwb_filename)\n",
    "io = pynwb.NWBHDF5IO(nwb_filename, mode='r')\n",
    "nwbf = io.read()\n",
    " \n",
    "sst = nwbf.session_start_time.timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Query: speed of a given animal, day, and epoch\n",
    "#### NWBFile (one animal), day, epoch --> ContinuousData (speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_module_name = 'Speed d{:d} e{:d}'.format(d['day'], d['epoch']) # HACKY--we should query on epoch directly\n",
    "speed_h5py = nwbf.modules['Behavior']['Speed'][speed_module_name]\n",
    "samples = pd.DataFrame(data=speed_h5py.data[()], columns=['speed'])\n",
    "speed = ContinuousData(samples=samples, sample_times=speed_h5py.timestamps[()])\n",
    "speed.valid_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Query: position of a given animal, day, and epoch\n",
    "#### NWBFile (one animal), day, epoch --> ContinuousData (position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_module_name = 'Position d{:d} e{:d}'.format(d['day'], d['epoch']) # HACKY--we should query on epoch directly\n",
    "position_h5py = nwbf.modules['Behavior']['Position'][position_module_name]\n",
    "# position_data = np.array(position_h5py.data[()])\n",
    "position_data = pd.DataFrame(data=position_h5py.data[()], columns=['x', 'y'])\n",
    "position = ContinuousData(position_data, position_h5py.timestamps[()])\n",
    "\n",
    "print('*** All position records for epoch ***')\n",
    "print('# of measurements = %d' % position.samples.shape[0])\n",
    "print('# of intervals = %d' % len(position.valid_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(position.valid_intervals.durations()))\n",
    "\n",
    "fig1 = plt.figure(1, figsize=(15,3))\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "plot_ContinuousData(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Query: spiking of a given animal and cluster\n",
    "#### NWBFile (one animal), cluster --> PointData (spiking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_t = nwbf.units['spike_times'][d['cluster_id']]\n",
    "valid_intervals = TimeIntervals(nwbf.units['obs_intervals'][d['cluster_id']])\n",
    "spiking_all = PointData(point_times=spikes_t, valid_intervals=valid_intervals)\n",
    "\n",
    "print('*** Spiking for cluster %s ***' % d['cluster_id'])\n",
    "print('# of spikes = %d' % spiking_all.point_times.shape[0])\n",
    "print('# of intervals = %d' % len(spiking_all.valid_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(spiking_all.valid_intervals.durations()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Query: Find spiking within all non-sleep epochs\n",
    "#### PointData (spiking), TimeIntervals (epochs) --> PointData (spiking)\n",
    "\n",
    "The resulting valid_intervals for spiking are the intersection of the valid_intervals for spiking data and the time intervals defining the non-sleep behavioral epochs. Presently, the epoch start/stop times are inferred from the behavioral data, as epoch start/stop times are not explicitly defined in FrankLab data structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get start/stop times for all non-sleep behavioral epochs (called 'run' epochs in FrankLab data)\n",
    "epoch_types = np.array(nwbf.epochs['epoch_type'][:])\n",
    "behav_epoch_indices = np.where(epoch_types=='run')[0]\n",
    "\n",
    "# Build a TimeIntervals query with start/stop times of non-sleep behavioral epochs\n",
    "behav_intervals = []\n",
    "for i in behav_epoch_indices:\n",
    "    epoch_start = nwbf.epochs['start_time'][i]\n",
    "    epoch_stop = nwbf.epochs['stop_time'][i]\n",
    "    behav_intervals.append([epoch_start, epoch_stop])\n",
    "behav_intervals = TimeIntervals(np.array(behav_intervals)) # convert to TimeIntervals for query\n",
    "\n",
    "# time_query on spiking during non-sleep behavioral epochs\n",
    "spiking_behav = spiking_all.time_query(behav_intervals)\n",
    "\n",
    "print('*** Spiking for cluster %s during non-sleep behavioral epochs ***' % d['cluster_id'])\n",
    "print('# of spikes = %d' % spiking_behav.point_times.shape[0])\n",
    "print('# of intervals = %d' % len(spiking_behav.valid_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(spiking_behav.valid_intervals.durations()))\n",
    "\n",
    "# Plot spiking\n",
    "spikeplots = [(spiking_all, 'All spiking'),\n",
    "              (spiking_behav, 'Spikes in\\nnon-sleep epochs')]\n",
    "\n",
    "fig1 = plt.figure(1, figsize=(15,3))\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "plot_PointData_multiple(spikeplots, axis=ax1)\n",
    "\n",
    "pass # suppress output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Query: Find spiking within a single behavioral epoch\n",
    "#### PointData (spiking), TimeIntervals (epoch) --> PointData (spiking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get epoch start/stop times from the NWB file\n",
    "epoch_start = nwbf.epochs['start_time'][d['epoch']-1]\n",
    "epoch_end = nwbf.epochs['stop_time'][d['epoch']-1]\n",
    "epoch_interval = TimeIntervals(np.array([epoch_start, epoch_end]))\n",
    "\n",
    "# time_query on spiking during the epoch\n",
    "spiking = spiking_all.time_query(epoch_interval)\n",
    "\n",
    "print('*** Spiking for cluster %s during epoch %d ***' % (d['cluster_id'], d['epoch']))\n",
    "print('# of spikes = %d' % spiking.point_times.shape[0])\n",
    "print('# of intervals = %d' % len(spiking.valid_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(spiking.valid_intervals.durations()))\n",
    "\n",
    "\n",
    "# Plot spiking\n",
    "spikeplots = [(spiking_all, 'All spiking'),\n",
    "              (spiking_behav, 'Spikes in\\nnon-sleep epochs'),\n",
    "              (spiking, 'Spikes in\\nepoch %s' % d['epoch'])]\n",
    "\n",
    "fig1 = plt.figure(1, figsize=(15,3))\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "plot_PointData_multiple(spikeplots, axis=ax1)\n",
    "\n",
    "fig2 = plt.figure(2, figsize=(15,2))\n",
    "ax2 = fig2.add_subplot(1, 1, 1)\n",
    "plot_PointData_multiple([spikeplots[2]], axis=ax2)\n",
    "ax2.set_title(\"Zooming in...\")\n",
    "\n",
    "pass # suppress output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Find time intervals where speed > threshold\n",
    "#### ContinuousData (speed), lambda function --> EventData (time periods where animal speed > threshold)\n",
    "This is an _analysis_, not a query, because we are not simply selecting a subset of a given datatype. i.e. We are not asking for a subset of the speed data, but rather for the intervals where it fulfills a lambda function. The lambda function could have been something different, like \"find the times of all upward threshold crossings, and then pad this by 5 seconds on either side.\". Regardless of how simple or complex the lambda function is, we consider this to be an analysis. Using the output of this to select a subset of the spiking data, however, is a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_threshold_fn = lambda x: x > c['speed_threshold']\n",
    "speed_events = speed.filter_intervals(speed_threshold_fn)\n",
    "\n",
    "print('*** Times where speed > threshold ***')\n",
    "print('# of events = %d' % len(speed_events.event_intervals))\n",
    "print('duration of events = %0.2f s' % np.sum(speed_events.durations()))\n",
    "print('# of valid intervals = %d' % len(speed_events.valid_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(speed_events.valid_durations()))\n",
    "\n",
    "# TODO: Plot continuous speed\n",
    "fig1 = plt.figure(1, figsize=(15,3))\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "plot_EventData(speed_events, axis=ax1)\n",
    "ax1.set_yticks([1])\n",
    "ax1.set_yticklabels(['Run events \\n(speed>threshold)']) # eventually use metadata from PointData object\n",
    "pass # suppress output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: spiking during time intervals where speed > threshold\n",
    "#### PointData (spiking), EventData (bouts where speed > threshold) --> PointData (spiking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiking_run = spiking.time_query(speed_events)  # Use the built-in time query method on PointProcess\n",
    "\n",
    "print('*** Spiking where speed > threshold ***')\n",
    "print('# of spikes = %d' % len(spiking_run.point_times))\n",
    "print('# of intervals = %d' % len(spiking_run.valid_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(spiking_run.valid_intervals.durations()))\n",
    "print()\n",
    "\n",
    "print(spiking_run)\n",
    "\n",
    "# Plot spiking\n",
    "fig1 = plt.figure(1, figsize=(15,1.5))\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "plot_PointData_multiple([(spiking_run, 'Spiking during run')], axis=ax1)\n",
    "\n",
    "pass # suppress output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Mark animal position at the time of each spike\n",
    "#### PointData (spiking), ContinuousData (position [m x 2]) --> PointData with marks (spike times with associated positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiking_run_mark_pos = spiking_run.mark_with_ContinuousData(position)\n",
    "\n",
    "print('*** Spiking where speed > threshold, marked with position ***')\n",
    "print('# of marked spikes = %d' % len(spiking_run_mark_pos.point_times))\n",
    "print('# of intervals = %d' % len(spiking_run_mark_pos.valid_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(spiking_run_mark_pos.valid_intervals.durations()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: Get animal locations during running events\n",
    "#### ContinuousData (position [m x 2]), EventData (bouts where speed > threshold) --> ContinuousData (position [m_new x 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_run = position.time_query(speed_events)\n",
    "\n",
    "print('*** Position where speed > threshold ***')\n",
    "print('# of samples = %d' % position_run.samples.shape[0])\n",
    "print('# of intervals = %d' % len(position_run.valid_intervals))\n",
    "print('duration of intervals = %0.2f s' % np.sum(position_run.valid_intervals.durations()))\n",
    "print()\n",
    "\n",
    "fig1 = plt.figure(1, figsize=(15,5))\n",
    "ax1 = fig1.add_subplot(4, 1, 1)\n",
    "plot_ContinuousData(position, axis=ax1)\n",
    "\n",
    "ax2 = fig1.add_subplot(4, 1, 2, sharex=ax1)\n",
    "plot_ContinuousData(speed, axis=ax2)\n",
    "\n",
    "ax3 = fig1.add_subplot(4, 1, 3, sharex=ax1)\n",
    "plot_EventData(speed_events, axis=ax3)\n",
    "\n",
    "ax4 = fig1.add_subplot(4, 1, 4, sharex=ax1)\n",
    "plot_ContinuousData(position_run, axis=ax4)\n",
    "\n",
    "print(position.sample_times[0])\n",
    "ax1.set_xlim(1136409500, 1136409600)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spikes by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(1, figsize=(15,15))\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "ax1.axis('equal')\n",
    "\n",
    "# Line showing the animal's movement during the entire epoch\n",
    "plt.plot(position.samples['x'], position.samples['y'], marker='', color='gray', label='Rat location', zorder=1)\n",
    "\n",
    "# Lines showing animal movement during each interval where it was running\n",
    "run_label = 'Rat location during movement'\n",
    "for ivl in position_run.valid_intervals:\n",
    "    ivl_data = position.time_query(TimeIntervals(ivl)).samples  # position at this valid interval \n",
    "    plt.plot(ivl_data['x'], ivl_data['y'], marker='', color='red', label=run_label, zorder=2)\n",
    "    run_label = '_' # omit later lines from legend\n",
    "\n",
    "# Markers for locations where unit spiked during animal running\n",
    "plt.scatter(spiking_run_mark_pos.marks['x'], spiking_run_mark_pos.marks['y'], marker='D', s=50, label='Location at spike times during movement', zorder=3)\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('X position (m)')\n",
    "ax1.set_ylabel('Y position (m)')\n",
    "ax1.set_title('Spike-position map for {} d{} e{} c{}, speed > {:0.1f} cm/s'.format(d['anim'], d['day'], d['epoch'], d['cluster_id'], (c['speed_threshold'] * 100)))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

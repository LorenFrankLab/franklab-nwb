{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "\n",
    "import pynwb\n",
    "import nspike_helpers as ns \n",
    "import query_helpers as qu\n",
    "import fl_apparatus as ap\n",
    "\n",
    "mdates.rcParams.update({'date.autoformatter.microsecond': '%H:%M:%S.%f'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug settings\n",
    "limit_num_of_tets = None # To speed up testing. Set to None to load all tets\n",
    "\n",
    "# Session-specific params\n",
    "# data_dir = '/opt/data46/FrankData/kkay/Bon/'\n",
    "data_dir = os.path.expanduser('~/Data/FrankData/kkay/Bon')\n",
    "anim = 'Bon' \n",
    "day = 4 # below we'll code date as 2006-Jan-'Day'\n",
    "\n",
    "# 'Wall clock' (i.e. actual) date and time of the Nspike time = 0 for this experiment.\n",
    "# NOTE: this is not the true zero_time, as we don't have easy access to that without digging in lab notebooks.\n",
    "# TODO: dig in lab notebooks, at least to get the date of recording.\n",
    "dataset_zero_time = datetime(2006, 1, day, 12, 0, 0, tzinfo=tz.gettz('US/Pacific'))\n",
    "\n",
    "# General params/presets\n",
    "file_create_date = datetime.now(tz.tzlocal())\n",
    "\n",
    "eeg_samprate = 1500.0 # Hz\n",
    "\n",
    "eeg_subdir = \"EEG\"\n",
    "epochs_file = \"times.mat\"\n",
    "tetinfo_file = \"tetinfo.mat\"\n",
    "NSpike_timestamps_per_sec = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_create_date)\n",
    "print(dataset_zero_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse inputs and create NWBfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_str = '%02d' % day\n",
    "\n",
    "nwb_filename = anim + day_str + '_test.nwb'\n",
    "\n",
    "# check the input arguments\n",
    "if not os.path.exists(data_dir):\n",
    "        print('Error: data_dir %s does not exist' % data_dir)\n",
    "        exit(-1)\n",
    "\n",
    "# get filename prefix and file locations\n",
    "prefix = anim.lower()\n",
    "eeg_path = os.path.join(data_dir, eeg_subdir)\n",
    "\n",
    "# Calculate the POSIX timestamp when Nspike clock = 0 (seconds)\n",
    "NSpike_posixtime_offset = dataset_zero_time.timestamp()\n",
    "\n",
    "# We'll still store NSpike/Trodes zero time in nwbfile.session_start_time, \n",
    "# so that we can recreate the experimental timestamps, even though that\n",
    "# violates the definition of session_start_time as zero time. We need some\n",
    "# other way to indicate that the timestamps are POSIX (easy: if they are over\n",
    "# a trillion, then they're POSIX!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbf = pynwb.NWBFile(\n",
    "           session_description='Converted NSpike data from %s' % data_dir,\n",
    "           identifier=anim+day_str,\n",
    "           session_start_time=dataset_zero_time,\n",
    "           file_create_date=file_create_date,\n",
    "           lab='Frank Laboratory',\n",
    "           experimenter='Mattias Karlsson',\n",
    "           institution='UCSF',\n",
    "           experiment_description='Recordings from awake behaving rat',\n",
    "           session_id=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create position, direction and speed\n",
    "position_list = []\n",
    "pos = pynwb.behavior.Position(spatial_series=position_list, \n",
    "                              name='Position')\n",
    "\n",
    "direction_list = []\n",
    "dir = pynwb.behavior.CompassDirection(spatial_series=direction_list, \n",
    "                                      name='Head Direction')\n",
    "\n",
    "speed_list = []\n",
    "speed = pynwb.behavior.BehavioralTimeSeries(time_series=speed_list, \n",
    "                                            name='Speed')\n",
    "\n",
    "# NOTE that day_inds is 0 based\n",
    "# time_list = {}\n",
    "# nwb_epoch = {}\n",
    "pos_files = ns.get_files_by_day(data_dir, prefix, 'pos')\n",
    "task_files = ns.get_files_by_day(data_dir, prefix, 'task')\n",
    "linpos_files = ns.get_files_by_day(data_dir, prefix, 'linpos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = ns.loadmat_ff(task_files[day], 'task')\n",
    "task_struct = mat[day]\n",
    "# find the pos file for this day and load it\n",
    "\n",
    "mat = ns.loadmat_ff(pos_files[day], 'pos')\n",
    "pos_struct = mat[day]\n",
    "\n",
    "mat = ns.loadmat_ff(linpos_files[day], 'linpos')\n",
    "linpos_struct = mat[day]\n",
    "# Fill in None for epochs that have no linpos data\n",
    "for k in task_struct.keys():\n",
    "    if k not in linpos_struct:\n",
    "        linpos_struct[k] = None\n",
    "\n",
    "# compile a list of time intervals in the pos struct (i.e. start/stop times of position data)\n",
    "# currently this is how epochs are defined in Matlab. The task struct, which contains metadata about\n",
    "# epochs, does not itself have start/stop times of the epoch.\n",
    "pos_time_ivls = []\n",
    "\n",
    "# Assume field order: (time,x,y,dir,vel)\n",
    "(time_idx, x_idx, y_idx, dir_idx, vel_idx) = range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_num, pos_epoch in pos_struct.items():\n",
    "\n",
    "    # convert times to POSIX time\n",
    "    timestamps = pos_epoch['data'][:,time_idx] + NSpike_posixtime_offset\n",
    "\n",
    "    # TODO: create a shared TimeSeries for timestamps, across all behavioral timeseries\n",
    "    # ?? timestamps_obj = pynwb.TimeSeries(timestamps=timestamps...)\n",
    "\n",
    "    # collect times of epoch start and end\n",
    "    pos_time_ivls.append([timestamps[0], timestamps[-1]])\n",
    "\n",
    "    m_per_pixel = pos_epoch['cmperpixel'][0,0]/100 # NWB wants meters per pixel\n",
    "\n",
    "    # we can also create new SpatialSeries for the position, direction and velocity information\n",
    "    #NOTE: Each new spatial series has to have a unique name.\n",
    "    pos.create_spatial_series(name='Position d%d e%d' % (day, epoch_num), \n",
    "                              timestamps = timestamps,\n",
    "                              data=pos_epoch['data'][:, (x_idx, y_idx)] * m_per_pixel,\n",
    "                              reference_frame='corner of video frame',\n",
    "                              #conversion=m_per_pixel,\n",
    "                              #unit='m'\n",
    "                              ) # *after* conversion\n",
    "\n",
    "    dir.create_spatial_series(name='Head Direction d%d e%d'% (day, epoch_num), \n",
    "                              timestamps=timestamps,\n",
    "                              data=pos_epoch['data'][:, dir_idx],\n",
    "                              reference_frame='0=facing top of video frame (?), positive clockwise (?)',\n",
    "                              #unit='radians'\n",
    "                              )\n",
    "\n",
    "    speed.create_timeseries(name='Speed d%d e%d' % (day, epoch_num),\n",
    "                             timestamps=timestamps,\n",
    "                             data=pos_epoch['data'][:, vel_idx] * m_per_pixel,\n",
    "                             unit='m/s',\n",
    "                             #conversion=m_per_pixel,\n",
    "                             description='smoothed movement speed estimate')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Speed <class 'pynwb.behavior.BehavioralTimeSeries'>\n",
       "Fields:\n",
       "  time_series: { Speed d4 e1 <class 'pynwb.base.TimeSeries'>,  Speed d4 e2 <class 'pynwb.base.TimeSeries'>,  Speed d4 e3 <class 'pynwb.base.TimeSeries'>,  Speed d4 e4 <class 'pynwb.base.TimeSeries'>,  Speed d4 e5 <class 'pynwb.base.TimeSeries'>,  Speed d4 e6 <class 'pynwb.base.TimeSeries'>,  Speed d4 e7 <class 'pynwb.base.TimeSeries'> }"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a Processing module for behavior\n",
    "behav_mod = nwbf.create_processing_module(name='Behavior', \n",
    "                                          description='Behavioral variables')\n",
    "# add the position, direction and speed data\n",
    "behav_mod.add_data_interface(pos)\n",
    "behav_mod.add_data_interface(dir)\n",
    "behav_mod.add_data_interface(speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('franklab_apparatus',)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns_path = \"franklab_apparatus.namespace.yaml\"\n",
    "pynwb.load_namespaces(ns_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------------------------------------------------------------\n",
    "# # The start/stop time of epochs in NWB will be drawn from the start/stop times of data in pos_struct.\n",
    "# # (Start/stop times of epochs are not explicitly defined in the Matlab task_struct.)\n",
    "# # ------------------------------------------------------------------\n",
    "epoch_tags = ''  # tags is currently a required column in epochs\n",
    "\n",
    "# # Add metadata columns to the epochs table.\n",
    "# # Note: in Bon data, epochs of type 'sleep' do not contain environment and exposure metadata\n",
    "nwbf.add_epoch_column(name='epoch_type', description='type of the epoch (i.e. run, sleep)')\n",
    "nwbf.add_epoch_column(name='environment', description='behavioral environment of the epoch (i.e. W-Track A)')\n",
    "nwbf.add_epoch_column(name='exposure', description='number of exposures to this environment')\n",
    "nwbf.add_epoch_column(name='task', description='behavioral task for this epoch')\n",
    "\n",
    "for epoch_num, task_epoch in task_struct.items():\n",
    "    # Required columns\n",
    "    epoch_start, epoch_stop = pos_time_ivls[epoch_num-1]  # start/stop times inferred from pos_struct\n",
    "    \n",
    "    # Optional metadata (some not present in 'sleep' epochs)\n",
    "    epoch_metadata_keys = task_epoch.keys()\n",
    "    if 'type' in epoch_metadata_keys:\n",
    "        epoch_type = task_epoch['type'][0]\n",
    "    else:\n",
    "        epoch_type = 'NA'\n",
    "    if 'environment' in epoch_metadata_keys:\n",
    "        epoch_env = task_epoch['environment'][0]\n",
    "    else:\n",
    "        epoch_env = 'NA'\n",
    "    if 'exposure' in epoch_metadata_keys:\n",
    "        epoch_exposure = task_epoch['exposure'][0]\n",
    "    else:\n",
    "        epoch_exposure = 'NA'\n",
    "        \n",
    "    # Create an Apparatus from the linpos for this epoch if it hasn't already been created\n",
    "    if epoch_env not in behav_mod.data_interfaces.keys():\n",
    "        appar = ap.get_apparatus(linpos_struct[epoch_num], epoch_env)\n",
    "        behav_mod.add_data_interface(appar)\n",
    "    \n",
    "    # Create a Task for this epoch, and store it in the behavior module if not already there.\n",
    "    # TODO: Is there a better way to do this without relying on the epoch_type??\n",
    "    appar_name = behav_mod.data_interfaces[epoch_env].name\n",
    "    if epoch_type == 'run':\n",
    "        task_name = 'Alternation on ' + appar_name\n",
    "        task_description = 'A hungry animal runs back and forth, drinking milk.'\n",
    "    else:\n",
    "        task_name = 'Sleep on ' + appar_name\n",
    "        task_description = 'A tired animal sleeps in a box.'\n",
    "    if task_name not in behav_mod.data_interfaces.keys():\n",
    "        task = ap.Task(name=task_name,\n",
    "                       description=task_description,\n",
    "                       apparatus=appar)\n",
    "        behav_mod.add_data_interface(task)\n",
    "    \n",
    "    # Add this epoch to the NWB file\n",
    "    # We include soft link to this task, which itself contains a link to the apparatus\n",
    "    nwbf.add_epoch(start_time=epoch_start,\n",
    "                   stop_time=epoch_stop,\n",
    "                   epoch_type=epoch_type,\n",
    "                   environment=epoch_env,\n",
    "                   exposure=epoch_exposure,\n",
    "                   task=behav_mod.data_interfaces[task_name],\n",
    "                   tags=epoch_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tetrode info\n",
    "Load in `tetinfo` struct and populate ElectrodeTable, electrode groups, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the electrode table.\n",
    "# The logic here is as follows:\n",
    "#   Each Tetrode gets its own ElectrodeGroup and ElectrodeTableRegion\n",
    "#   Each individual recording channel gets its own row in nwbfile.electrodes\n",
    "\n",
    "# we first create the ElectrodeTable that all the electrodes will go into\n",
    "nchan_per_tetrode = 4 #these files all contain tetrodes, so we assume four channels\n",
    "tetinfo_filename = \"%s/%s%s\" % (data_dir, prefix, tetinfo_file)\n",
    "recording_device = nwbf.create_device(name='NSpike acquisition system')\n",
    "tet_electrode_group = {}\n",
    "tet_electrode_table_region = {}\n",
    "lfp_electrode_table_region = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Using tetrode numbers:\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "mat = ns.loadmat_ff(tetinfo_filename, 'tetinfo')\n",
    "#only look at first epoch because rest are duplicates\n",
    "tets = mat[day][1]\n",
    "\n",
    "# For debugging, limit number of tets to import\n",
    "subset_keys = sorted(tets.keys())[0:limit_num_of_tets]\n",
    "tets = {k:v for (k,v) in tets.items() if k in subset_keys}\n",
    "\n",
    "print(limit_num_of_tets)\n",
    "print(\"Using tetrode numbers:\")\n",
    "print(subset_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tets[1]['depth'][0,0][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kenny's data has a nested [day][epoch][tetrode] structure but duplicates the info across epochs, so we can just\n",
    "# use the first epoch for everything\n",
    "chan_num = 0 # this will hold an incrementing channel number for the entire day of data\n",
    "for tet_num, tet in tets.items():\n",
    "    #print('making electrode group for day %d, tet %d' % (day, tet_ind))\n",
    "    # go through the list of fields\n",
    "    hemisphere = '?'\n",
    "    # tet.area/.subarea are 1-d arrays of Unicode strings\n",
    "    area = str(tet['area'][0]) if 'area' in tet else '?' # h5py barfs on numpy.str_ type objects?\n",
    "    if 'sub_area' in tet: \n",
    "        sub_area = str(tet['sub_area'][0]) # h5py barfs on numpy.str_ type objects?\n",
    "        location = area + ' ' + sub_area\n",
    "    else:\n",
    "        sub_area = '?'\n",
    "        location = area \n",
    "\n",
    "    # tet.depth is a 1x1 cell array in tetinfo struct for some reason (multiple depths?)\n",
    "    # (which contains the expected 1x1 numeric array)\n",
    "    coord = [np.nan, np.nan, tet['depth'][0, 0][0, 0] / 12 / 80 * 25.4] if 'depth' in tet else [np.nan, np.nan, np.nan]\n",
    "    impedance = np.nan\n",
    "    filtering = 'unknown - likely 600Hz-6KHz'\n",
    "\n",
    "    channel_location = [location, location, location, location]\n",
    "    channel_coordinates = [coord, coord, coord, coord]\n",
    "    electrode_name = \"%02d-%02d\" % (day, tet_num)\n",
    "    description = \"tetrode {tet_num} located in {location} on day {day}\".format(tet_num=tet_num,\n",
    "                                                                               location=location,\n",
    "                                                                               day=day)\n",
    "\n",
    "    # we need to create an electrode group for this tetrode\n",
    "    tet_electrode_group[tet_num] = nwbf.create_electrode_group(name=electrode_name,\n",
    "                                                        description=description,\n",
    "                                                        location=location,\n",
    "                                                        device=recording_device)\n",
    "\n",
    "    for i in range(nchan_per_tetrode):\n",
    "            # now add an electrode\n",
    "            nwbf.add_electrode(x=coord[0],\n",
    "                               y=coord[1],\n",
    "                               z=coord[2],\n",
    "                               imp=impedance,\n",
    "                               location=location,\n",
    "                               filtering=filtering,\n",
    "                               group=tet_electrode_group[tet_num],\n",
    "                               group_name=tet_electrode_group[tet_num].name, # not in docstring??\n",
    "                               id=chan_num)\n",
    "            chan_num = chan_num + 1\n",
    "\n",
    "    # now that we've created four entries, one for each channel of the tetrode, we create a new\n",
    "    # electrode table region for this tetrode and number it appropriately\n",
    "    table_region_description = 'ntrode %d region' % tet_num\n",
    "    table_region_name = '%d' % tet_num\n",
    "    tet_electrode_table_region[tet_num] = nwbf.create_electrode_table_region(\n",
    "        region=list(range(chan_num-nchan_per_tetrode,chan_num)),\n",
    "        description=table_region_description,\n",
    "        # BUG #679: name must be 'electrodes' or NWB file will not be readable\n",
    "        name='electrodes') #        name=table_region_name)\n",
    "\n",
    "\n",
    "\n",
    "    # Also create electrode_table_regions for each tetrode's LFP recordings\n",
    "    # (Assume that LFP is taken from the first channel)\n",
    "    lfp_electrode_table_region[tet_num] = nwbf.create_electrode_table_region(\n",
    "        region=[chan_num-nchan_per_tetrode],\n",
    "        description=table_region_description,\n",
    "        # BUG #679: name must be 'electrodes' or NWB file will not be readable\n",
    "        name='electrodes') #        name=table_region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tet_electrode_table_region[1].region\n",
    "# nwbf.ec_electrode_groups['03-01'].description\n",
    "# tet_electrode_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing LFP data for day  4\n",
      " -> tet_num: 1\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-01.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-01.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-01.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-01.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-01.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-01.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-01.mat\n",
      " -> tet_num: 2\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-02.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-02.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-02.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-02.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-02.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-02.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-02.mat\n",
      " -> tet_num: 3\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-03.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-03.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-03.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-03.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-03.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-03.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-03.mat\n",
      " -> tet_num: 4\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-04.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-04.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-04.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-04.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-04.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-04.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-04.mat\n",
      " -> tet_num: 5\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-05.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-05.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-05.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-05.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-05.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-05.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-05.mat\n",
      " -> tet_num: 6\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-06.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-06.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-06.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-06.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-06.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-06.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-06.mat\n",
      " -> tet_num: 7\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-07.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-07.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-07.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-07.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-07.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-07.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-07.mat\n",
      " -> tet_num: 8\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-08.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-08.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-08.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-08.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-08.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-08.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-08.mat\n",
      " -> tet_num: 10\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-10.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-10.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-10.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-10.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-10.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-10.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-10.mat\n",
      " -> tet_num: 11\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-11.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-11.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-11.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-11.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-11.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-11.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-11.mat\n",
      " -> tet_num: 12\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-12.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-12.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-12.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-12.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-12.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-12.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-12.mat\n",
      " -> tet_num: 13\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-13.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-13.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-13.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-13.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-13.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-13.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-13.mat\n",
      " -> tet_num: 14\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-14.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-14.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-14.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-14.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-14.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-14.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-14.mat\n",
      " -> tet_num: 15\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-15.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-15.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-15.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-15.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-15.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-15.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-15.mat\n",
      " -> tet_num: 17\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-17.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-17.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-17.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-17.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-17.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-17.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-17.mat\n",
      " -> tet_num: 18\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-18.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-18.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-18.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-18.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-18.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-18.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-18.mat\n",
      " -> tet_num: 19\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-19.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-19.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-19.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-19.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-19.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-19.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-19.mat\n",
      " -> tet_num: 20\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-20.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-20.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-20.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-20.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-20.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-20.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-20.mat\n",
      " -> tet_num: 21\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-21.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-21.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-21.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-21.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-21.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-21.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-21.mat\n",
      " -> tet_num: 22\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-22.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-22.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-22.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-22.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-22.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-22.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-22.mat\n",
      " -> tet_num: 23\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-23.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-23.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-23.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-23.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-23.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-23.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-23.mat\n",
      " -> tet_num: 24\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-24.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-24.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-24.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-24.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-24.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-24.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-24.mat\n",
      " -> tet_num: 25\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-25.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-25.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-25.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-25.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-25.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-25.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-25.mat\n",
      " -> tet_num: 27\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-27.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-27.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-27.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-27.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-27.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-27.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-27.mat\n",
      " -> tet_num: 28\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-28.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-28.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-28.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-28.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-28.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-28.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-28.mat\n",
      " -> tet_num: 29\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-29.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-29.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-29.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-29.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-29.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-29.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-29.mat\n",
      " -> tet_num: 30\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-1-30.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-2-30.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-3-30.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-4-30.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-5-30.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-6-30.mat\n",
      "loading file: /Users/ericmiller/Data/FrankData/kkay/Bon/EEG/boneeg04-7-30.mat\n",
      "CPU times: user 11.7 s, sys: 3.39 s, total: 15.1 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eeg_files = ns.get_eeg_by_day(eeg_path, prefix, 'eeg')\n",
    "lfp_data = []\n",
    "\n",
    "lfp = pynwb.ecephys.LFP(electrical_series=lfp_data)\n",
    "# read data from EEG/*eeg*.mat files and build TimeSeries object\n",
    "\n",
    "print('processing LFP data for day %2d' % day)\n",
    "for tet_num in tets.keys():\n",
    "    print(' -> tet_num: %d' % tet_num)\n",
    "    timestamps, data = ns.build_day_eeg(eeg_files[day][tet_num], eeg_samprate)\n",
    "    timestamps += NSpike_posixtime_offset\n",
    "    name = \"{prefix}eeg-{day}-{tet}\".format(prefix=prefix, day=day, tet=tet_num)\n",
    "    lfp.create_electrical_series(name=name, \n",
    "                                 data=data / 1000, # convert mV to V, as expected\n",
    "                                 electrodes=lfp_electrode_table_region[tet_num],\n",
    "                                 timestamps=timestamps)\n",
    "nwbf.add_acquisition(lfp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unit metadata first\n",
    "# External clustering software gives names for each cluster--we want to preserve these\n",
    "nwbf.add_unit_column('cluster_name',  '(str) cluster name from clustering software')\n",
    "\n",
    "# # For tetrode data, this will usually be all channels in the tetrode (2018Dec03--now in spec with 'electrodes' field?)\n",
    "# nwbf.add_unit_column('neighborhood',  '(electrodeTableRegion) list of electrodes on which spikes were clustered')\n",
    "\n",
    "# # AKA 'Valid_times'--the times during which a spike from this cluster could have possibly been observed.\n",
    "# # (handle periods between behavior epochs, acquisition system dropouts, etc.)\n",
    "# nwbf.add_unit_column('obs_intervals', '(intervalSeries) Observation Intervals for the spike times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading spikes file :/Users/ericmiller/Data/FrankData/kkay/Bon/bonspikes04.mat\n"
     ]
    }
   ],
   "source": [
    "#get the spike times from the spikes files\n",
    "#each cluster gets a unique number starting at zero\n",
    "\n",
    "spike_files = ns.get_files_by_day(data_dir, prefix, 'spikes')\n",
    "print('\\nLoading spikes file :' + spike_files[day])\n",
    "mat = ns.loadmat_ff(spike_files[day], 'spikes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_unit = []\n",
    "obs_intervals = {}\n",
    "cluster_by_tet = {}\n",
    "cluster_id = 0\n",
    "\n",
    "# Matlab structs are nested by: day, epoch, tetrode, cluster, but we will want to save all spikes from a give cluster\n",
    "# *across multiple epochs* in same spike list. So we rearrange the nested matlab structures for convenience. We \n",
    "# create a nested dict, keyed by 1) tetrode, 2) cluster number, then 3) epoch. NB the keys are 1-indexed, to be \n",
    "# consistent with the original data collection. (We only process one day at a time for now, so no need to nest days).\n",
    "\n",
    "spike_struct = mat[day]\n",
    "for epoch_num, espikes in spike_struct.items():\n",
    "    for tet_num, tspikes in espikes.items():\n",
    "        # respect tet subset selection done above\n",
    "        if tet_num not in tets.keys():\n",
    "            continue\n",
    "        if tet_num not in cluster_by_tet.keys():\n",
    "            cluster_by_tet[tet_num] = {}\n",
    "        for cluster_num, cspikes in tspikes.items():\n",
    "            if cluster_num not in cluster_by_tet[tet_num].keys():\n",
    "                cluster_by_tet[tet_num][cluster_num] = {}\n",
    "            cluster_by_tet[tet_num][cluster_num][epoch_num] = cspikes\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding cluster id:   0, name: d4 t1 c1\n",
      "Adding cluster id:   1, name: d4 t1 c2\n",
      "Adding cluster id:   2, name: d4 t1 c3\n",
      "Adding cluster id:   3, name: d4 t1 c4\n",
      "Adding cluster id:   4, name: d4 t1 c5\n",
      "Adding cluster id:   5, name: d4 t1 c6\n",
      "Adding cluster id:   6, name: d4 t1 c7\n",
      "Adding cluster id:   7, name: d4 t1 c8\n",
      "Adding cluster id:   8, name: d4 t1 c9\n",
      "Adding cluster id:   9, name: d4 t1 c10\n",
      "Adding cluster id:  10, name: d4 t2 c1\n",
      "Adding cluster id:  11, name: d4 t2 c2\n",
      "Adding cluster id:  12, name: d4 t2 c3\n",
      "Adding cluster id:  13, name: d4 t2 c4\n",
      "Adding cluster id:  14, name: d4 t2 c5\n",
      "Adding cluster id:  15, name: d4 t4 c1\n",
      "Adding cluster id:  16, name: d4 t4 c2\n",
      "Adding cluster id:  17, name: d4 t5 c1\n",
      "Adding cluster id:  18, name: d4 t5 c2\n",
      "Adding cluster id:  19, name: d4 t5 c3\n",
      "Adding cluster id:  20, name: d4 t5 c4\n",
      "Adding cluster id:  21, name: d4 t5 c5\n",
      "Adding cluster id:  22, name: d4 t7 c1\n",
      "Adding cluster id:  23, name: d4 t10 c1\n",
      "Adding cluster id:  24, name: d4 t10 c2\n",
      "Adding cluster id:  25, name: d4 t10 c3\n",
      "Adding cluster id:  26, name: d4 t10 c4\n",
      "Adding cluster id:  27, name: d4 t11 c1\n",
      "Adding cluster id:  28, name: d4 t11 c2\n",
      "Adding cluster id:  29, name: d4 t11 c3\n",
      "Adding cluster id:  30, name: d4 t11 c4\n",
      "Adding cluster id:  31, name: d4 t11 c5\n",
      "Adding cluster id:  32, name: d4 t12 c1\n",
      "Adding cluster id:  33, name: d4 t12 c2\n",
      "Adding cluster id:  34, name: d4 t12 c3\n",
      "Adding cluster id:  35, name: d4 t13 c1\n",
      "Adding cluster id:  36, name: d4 t13 c2\n",
      "Adding cluster id:  37, name: d4 t13 c3\n",
      "Adding cluster id:  38, name: d4 t13 c4\n",
      "Adding cluster id:  39, name: d4 t14 c1\n",
      "Adding cluster id:  40, name: d4 t14 c2\n",
      "Adding cluster id:  41, name: d4 t14 c3\n",
      "Adding cluster id:  42, name: d4 t14 c4\n",
      "Adding cluster id:  43, name: d4 t14 c5\n",
      "Adding cluster id:  44, name: d4 t14 c6\n",
      "Adding cluster id:  45, name: d4 t14 c7\n",
      "Adding cluster id:  46, name: d4 t17 c1\n",
      "Adding cluster id:  47, name: d4 t18 c1\n",
      "Adding cluster id:  48, name: d4 t18 c2\n",
      "Adding cluster id:  49, name: d4 t18 c3\n",
      "Adding cluster id:  50, name: d4 t18 c4\n",
      "Adding cluster id:  51, name: d4 t18 c5\n",
      "Adding cluster id:  52, name: d4 t18 c6\n",
      "Adding cluster id:  53, name: d4 t18 c7\n",
      "Adding cluster id:  54, name: d4 t19 c1\n",
      "Adding cluster id:  55, name: d4 t19 c2\n",
      "Adding cluster id:  56, name: d4 t19 c3\n",
      "Adding cluster id:  57, name: d4 t20 c1\n",
      "Adding cluster id:  58, name: d4 t20 c2\n",
      "Adding cluster id:  59, name: d4 t20 c3\n",
      "Adding cluster id:  60, name: d4 t20 c4\n",
      "Adding cluster id:  61, name: d4 t20 c5\n",
      "Adding cluster id:  62, name: d4 t20 c6\n",
      "Adding cluster id:  63, name: d4 t20 c8\n",
      "Adding cluster id:  64, name: d4 t22 c1\n",
      "Adding cluster id:  65, name: d4 t22 c2\n",
      "Adding cluster id:  66, name: d4 t22 c3\n",
      "Adding cluster id:  67, name: d4 t23 c1\n",
      "Adding cluster id:  68, name: d4 t23 c2\n",
      "Adding cluster id:  69, name: d4 t27 c1\n",
      "Adding cluster id:  70, name: d4 t29 c1\n",
      "Adding cluster id:  71, name: d4 t29 c2\n",
      "Adding cluster id:  72, name: d4 t29 c3\n",
      "Adding cluster id:  73, name: d4 t29 c4\n"
     ]
    }
   ],
   "source": [
    "# now we create the SpikeEventStructures and their containing EventWaveform objects\n",
    "colidx_timestamps = 0\n",
    "\n",
    "for tet_num in cluster_by_tet.keys():\n",
    "    obs_intervals[tet_num] = {}\n",
    "    for cluster_num in cluster_by_tet[tet_num].keys():\n",
    "        cluster_name = 'd%d t%d c%d' % (day, tet_num, cluster_num)\n",
    "        print('Adding cluster id: %3d, name: %s' % (cluster_id, cluster_name))\n",
    "\n",
    "        cluster_tmp = cluster_by_tet[tet_num][cluster_num]\n",
    "\n",
    "#         # construct a full data array and a parallel list of observation intervals\n",
    "#         obs_intervals[tet_num][cluster_num] = pynwb.misc.IntervalSeries(\n",
    "#                                                     name = cluster_name,\n",
    "#                                                     description = 'Observation intervals for spikes from cluster ' +\n",
    "#                                                     str(cluster_num) + ' on tetrode ' + str(tet_num))\n",
    "        obs_intervals[tet_num][cluster_num] = np.zeros([0,2])\n",
    "\n",
    "        spikes_ep = []\n",
    "        for epoch in cluster_tmp.keys():\n",
    "            if cluster_tmp[epoch]['data'].shape[0]:\n",
    "                spikes_ep.append(cluster_tmp[epoch]['data'][:,colidx_timestamps] + NSpike_posixtime_offset)\n",
    "            for obs_intervals_cl_ep in cluster_tmp[epoch]['timerange']:\n",
    "                # 'timerange' for each cell is given in NSpike timestamp units\n",
    "                obs_int = (obs_intervals_cl_ep.T.astype(float)/NSpike_timestamps_per_sec) + NSpike_posixtime_offset\n",
    "                obs_intervals[tet_num][cluster_num] = np.append(obs_intervals[tet_num][cluster_num], [obs_int], axis=0)\n",
    "                #                obs_intervals[tet_num][cluster_num].add_interval(*obs_int)\n",
    "\n",
    "        spiketimes = np.concatenate(spikes_ep)\n",
    "\n",
    "        # Add Observation Intervals to nwbfile willy-nilly (1 per cluster), \n",
    "        # so that we can successfully refer to them in the Unit metadata table\n",
    "#        spike_mod.add_data_interface(obs_intervals[tet_num][cluster_num])\n",
    "\n",
    "#         nwbf.add_unit(data = {'cluster_name': cluster_name, \n",
    "#                               'elec_group': tet_electrode_group[tet_num], \n",
    "#                               # can't just refer to electrode_table_region itself?: are never added to nwbfile to \n",
    "#                               # begin with. Instead, use 'data' field, which is a list of electrodeTable indices.\n",
    "# #                               'neighborhood': tet_electrode_table_region[tet_num], # tet_electrode_table_region[tet_num].data, \n",
    "#                               'obs_intervals': obs_intervals[tet_num][cluster_num]},\n",
    "#                       id = cluster_id)\n",
    "\n",
    "#         spike_UnitTimes.add_spike_times(cluster_id, spiketimes)\n",
    "\n",
    "        nwbf.add_unit(spike_times= spiketimes,\n",
    "                      electrodes=tet_electrode_table_region[tet_num].data, # wants list of electrode ids, not an electrodeTableRegion\n",
    "#                       electrode_group=[tet_electrode_group[tet_num]], # we can't figure out what is an acceptable input, here:\n",
    "#                                                                       # TypeError: incorrect type for 'container' (got 'list', expected 'Builder, Container or ReferenceBuilder')\n",
    "                      cluster_name=cluster_name, \n",
    "                      obs_intervals=obs_intervals[tet_num][cluster_num],\n",
    "                      id = cluster_id)\n",
    "\n",
    "        cluster_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out NWBfile!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote nwb file: Bon04_test.nwb\n"
     ]
    }
   ],
   "source": [
    "# make an NWBFile\n",
    "with pynwb.NWBHDF5IO(nwb_filename, mode='w') as iow:\n",
    "    iow.write(nwbf)\n",
    "print('Wrote nwb file: ' + nwb_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]\n",
      "(\n",
      "cluster_name <class 'pynwb.core.VectorData'>\n",
      "Fields:\n",
      "  description: (str) cluster name from clustering software\n",
      ", \n",
      "spike_times_index <class 'pynwb.core.VectorIndex'>\n",
      "Fields:\n",
      "  target: spike_times <class 'pynwb.core.VectorData'>\n",
      ", \n",
      "spike_times <class 'pynwb.core.VectorData'>\n",
      "Fields:\n",
      "  description: the spike times for each unit\n",
      ", \n",
      "obs_intervals_index <class 'pynwb.core.VectorIndex'>\n",
      "Fields:\n",
      "  target: obs_intervals <class 'pynwb.core.VectorData'>\n",
      ", \n",
      "obs_intervals <class 'pynwb.core.VectorData'>\n",
      "Fields:\n",
      "  description: the observation intervals for each unit\n",
      ", \n",
      "electrodes_index <class 'pynwb.core.VectorIndex'>\n",
      "Fields:\n",
      "  target: electrodes <class 'pynwb.core.DynamicTableRegion'>\n",
      ", \n",
      "electrodes <class 'pynwb.core.DynamicTableRegion'>\n",
      "Fields:\n",
      "  description: the electrodes that each spike unit came from\n",
      "  table: electrodes <class 'pynwb.core.DynamicTable'>\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(nwbf.electrodes.id.data)\n",
    "print(nwbf.units.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read our NWBfile, and check some roundtrip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = pynwb.NWBHDF5IO(nwb_filename, mode='r')\n",
    "nwbf_read = io.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(423,)\n",
      "d4 t1 c2\n",
      "[[1.13640580e+09 1.13640714e+09]\n",
      " [1.13640726e+09 1.13640820e+09]\n",
      " [1.13640828e+09 1.13640923e+09]\n",
      " [1.13640936e+09 1.13641030e+09]\n",
      " [1.13641038e+09 1.13641161e+09]\n",
      " [1.13641219e+09 1.13641313e+09]\n",
      " [1.13641331e+09 1.13641415e+09]]\n",
      "[[1.13640580e+09 1.13640714e+09]\n",
      " [1.13640726e+09 1.13640820e+09]\n",
      " [1.13640828e+09 1.13640923e+09]\n",
      " [1.13640936e+09 1.13641030e+09]\n",
      " [1.13641038e+09 1.13641161e+09]\n",
      " [1.13641219e+09 1.13641313e+09]\n",
      " [1.13641331e+09 1.13641415e+09]]\n"
     ]
    }
   ],
   "source": [
    "cl_id = 1\n",
    "print(nwbf_read.units.get_unit_spike_times(cl_id).shape)\n",
    "print(nwbf_read.units['cluster_name'][cl_id])\n",
    "print(nwbf_read.units['obs_intervals'][cl_id])\n",
    "print(nwbf_read.units.get_unit_obs_intervals(cl_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(nwbf.epochs['epoch_type'][:]) == 'run')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one of the electrical_series objects and work with it.\n",
    "example_es_name, example_es = list(nwbf_read.get_acquisition('LFP').electrical_series.items())[-1]\n",
    "nwbf_read.get_acquisition('LFP').electrical_series\n",
    "\n",
    "def fmt_sec_from_midnight (x, pos):\n",
    "    x_posix = mdates.num2epoch(x)\n",
    "    x_dt = mdates.num2date(x) \n",
    "    prev_midnight = x_dt.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    return (x_dt - prev_midnight).total_seconds()\n",
    "#    return \"%0.6f\" % mdates.num2epoch(x)\n",
    "\n",
    "fig1 = plt.figure(1, figsize=(15,10))\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "print(ax1.xaxis.major.formatter)\n",
    "xtick_locator = mticker.AutoLocator()\n",
    "xtick_formatter = mticker.FuncFormatter(qu.fmt_truncate_posix)\n",
    "# xtick_formatter = mdates.AutoDateFormatter(xtick_locator)\n",
    "# xtick_formatter = mticker.ScalarFormatter(xtick_locator)\n",
    "\n",
    "\n",
    "for i in [1]: #range(len(list(nwbf_read.get_acquisition('LFP').electrical_series.items()))):\n",
    "    example_es_name, example_es = list(nwbf_read.get_acquisition('LFP').electrical_series.items())[i]\n",
    "    nwbf_read.get_acquisition('LFP').electrical_series\n",
    "    #ts = (example_es.timestamps[-1001:-1]*1e9).astype('datetime64[ns]')\n",
    "    ts = example_es.timestamps[-10001:-1] \n",
    "    print(\"plot #%d\" % i)\n",
    "    ax1.plot(ts, example_es.data[0:10000] * 1000)\n",
    "\n",
    "ax1.set_title(example_es_name)\n",
    "ax1.set_xlabel('Time (s)')\n",
    "# ax1.set_xlabel('Time (s; prefix = 113615\\u2026)')\n",
    "ax1.set_ylabel('Amplitude (mV)')\n",
    "ax1.xaxis.set_major_locator(xtick_locator)\n",
    "ax1.xaxis.set_major_formatter(xtick_formatter)\n",
    "print(ax1.xaxis.major.formatter)\n",
    "\n",
    "\n",
    "# xtick_locator = mdates.AutoDateLocator()\n",
    "\n",
    "\n",
    "#fig1.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an NWB File with Frank Lab data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pynwb\n",
    "\n",
    "# General dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Time\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "\n",
    "# Helpers for parsing Frank Lab Matlab data\n",
    "import nspike_helpers as ns \n",
    "import query_helpers as qu\n",
    "\n",
    "# Frank Lab PyNWB extensions and extension-related helpers\n",
    "import fl_extension as fle\n",
    "import fl_extension_helpers as flh\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "mdates.rcParams.update({'date.autoformatter.microsecond': '%H:%M:%S.%f'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which data do you want to load?\n",
    "\n",
    "We will create an NWB file storing data from one experimental day for one animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to directory where the Frank Lab CRCNS data is located\n",
    "data_dir = os.path.expanduser('~/Data/FrankData/KKay/Bon')\n",
    "\n",
    "day = 4\n",
    "animal = 'Bon'\n",
    "    \n",
    "# Date and time this experiment was actually conducted\n",
    "dataset_zero_time = datetime(2006, 1, day, 12, 0, 0, tzinfo=tz.gettz('US/Pacific'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the new PyNWB object\n",
    "\n",
    "The PyNWB object provides an API (i.e. set of easily-used functions) that allow us to store our data in the\n",
    "appropriate places for eventually saving as a valid NWB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the top-level structure of our new (still mostly empty) PyNWB object:\n",
      "\n",
      "root <class 'pynwb.file.NWBFile'>\n",
      "Fields:\n",
      "  acquisition: { }\n",
      "  analysis: { }\n",
      "  devices: { }\n",
      "  electrode_groups: { }\n",
      "  epoch_tags: {}\n",
      "  experiment_description: Recordings from awake behaving rat\n",
      "  experimenter: Mattias Karlsson\n",
      "  ic_electrodes: { }\n",
      "  imaging_planes: { }\n",
      "  institution: UCSF\n",
      "  lab: Frank Laboratory\n",
      "  lab_meta_data: { }\n",
      "  modules: { }\n",
      "  ogen_sites: { }\n",
      "  session_id: /Users/ericmiller/Data/FrankData/KKay/Bon\n",
      "  stimulus: { }\n",
      "  stimulus_template: { }\n",
      "  time_intervals: { }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nwbf = pynwb.NWBFile(\n",
    "           session_description='Frank Lab CRCNS data for animal {0}, day {1}'.format(animal, day),\n",
    "           identifier='{0}{1:04}'.format(animal, day),\n",
    "           session_start_time=dataset_zero_time,\n",
    "           file_create_date=datetime.now(tz.tzlocal()),\n",
    "           lab='Frank Laboratory',\n",
    "           experimenter='Mattias Karlsson',\n",
    "           institution='UCSF',\n",
    "           experiment_description='Recordings from awake behaving rat',\n",
    "           session_id=data_dir)\n",
    "\n",
    "print(\"Here is the top-level structure of our new (still mostly empty) PyNWB object:\")\n",
    "print(nwbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize PyNWB objects for storing behavioral timeseries data\n",
    "\n",
    "PyNWB provides several datatypes for specific kinds of behavior data. This allows anyone using PyNWB to know what kinds of data are stored in which places in the PyNWB file. However, all of these are examples of timeseries data (i.e. data with assocaited timestamps). Here, we use the following:\n",
    "- spatial position (x/y) will be stored in a [Position](https://pynwb.readthedocs.io/en/latest/pynwb.behavior.html#pynwb.behavior.Position) object\n",
    "- head direction (angle) will be stored in a [CompassDirection](https://pynwb.readthedocs.io/en/latest/pynwb.behavior.html#pynwb.behavior.CompassDirection) object\n",
    "- speed (m/s) will be stored in a more general [BehavioralTimeSeries](https://pynwb.readthedocs.io/en/latest/pynwb.behavior.html#pynwb.behavior.BehavioralTimeSeries) object\n",
    "\n",
    "Each of these datatypes are a [MultiContainerInterface](https://pynwb.readthedocs.io/en/latest/pynwb.core.html#pynwb.core.MultiContainerInterface), which just means that we can store multiple instances of the same datatype. For example, a single [BehavioralTimeSeries](https://pynwb.readthedocs.io/en/latest/pynwb.behavior.html#pynwb.behavior.BehavioralTimeSeries), which we use for storing speed data, can store multiple [TimeSeries](https://pynwb.readthedocs.io/en/latest/pynwb.base.html#pynwb.base.TimeSeries) objects, such as for the speed of each epoch. We will use this feature to store the animal's speed for each epoch as a unique [TimeSeries](https://pynwb.readthedocs.io/en/latest/pynwb.base.html#pynwb.base.TimeSeries) within the same \n",
    "overarching [BehavioralTimeSeries](https://pynwb.readthedocs.io/en/latest/pynwb.behavior.html#pynwb.behavior.BehavioralTimeSeries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the PyNWB objects where we will store behavior data:\n",
      "\n",
      "Position <class 'pynwb.behavior.Position'>\n",
      "Fields:\n",
      "  spatial_series: { }\n",
      "\n",
      "\n",
      "Head Direction <class 'pynwb.behavior.CompassDirection'>\n",
      "Fields:\n",
      "  spatial_series: { }\n",
      "\n",
      "\n",
      "Speed <class 'pynwb.behavior.BehavioralTimeSeries'>\n",
      "Fields:\n",
      "  time_series: { }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "position = pynwb.behavior.Position(name='Position')\n",
    "head_dir = pynwb.behavior.CompassDirection(name='Head Direction')\n",
    "speed = pynwb.behavior.BehavioralTimeSeries(name='Speed')\n",
    "\n",
    "print(\"Here are the PyNWB objects where we will store behavior data:\")\n",
    "print(position)\n",
    "print(head_dir)\n",
    "print(speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import animal behavior data\n",
    "Parse behavioral data from the old Frank Lab Matlab files and store the data in the PyNWB datatypes we initialized above.\n",
    "We store the behavioral data for each epoch in this day as a separate timeseries within the same overarching PyNWB behavior object. \n",
    "For example, we add the animal's 2D spatial position for a given epoch by calling the [create_spatial_series](https://pynwb.readthedocs.io/en/latest/pynwb.behavior.html?highlight=create_spatial_series#pynwb.behavior.Position.create_spatial_series) method on the \n",
    "Position object, giving it a unique name. Similarly, for speed we use the [create_timeseries](https://pynwb.readthedocs.io/en/latest/pynwb.behavior.html?highlight=create_spatial_series#pynwb.behavior.BehavioralTimeSeries.create_timeseries) method on the BehavioralTimeSeries object\n",
    "to add the animal's speed for this epoch and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the same PyNWB objects, now filled with behavior data from each epoch:\n",
      "\n",
      "Position <class 'pynwb.behavior.Position'>\n",
      "Fields:\n",
      "  spatial_series: { Position d4 e1 <class 'pynwb.behavior.SpatialSeries'>,  Position d4 e2 <class 'pynwb.behavior.SpatialSeries'>,  Position d4 e3 <class 'pynwb.behavior.SpatialSeries'>,  Position d4 e4 <class 'pynwb.behavior.SpatialSeries'>,  Position d4 e5 <class 'pynwb.behavior.SpatialSeries'>,  Position d4 e6 <class 'pynwb.behavior.SpatialSeries'>,  Position d4 e7 <class 'pynwb.behavior.SpatialSeries'> }\n",
      "\n",
      "\n",
      "Head Direction <class 'pynwb.behavior.CompassDirection'>\n",
      "Fields:\n",
      "  spatial_series: { Head Direction d4 e1 <class 'pynwb.behavior.SpatialSeries'>,  Head Direction d4 e2 <class 'pynwb.behavior.SpatialSeries'>,  Head Direction d4 e3 <class 'pynwb.behavior.SpatialSeries'>,  Head Direction d4 e4 <class 'pynwb.behavior.SpatialSeries'>,  Head Direction d4 e5 <class 'pynwb.behavior.SpatialSeries'>,  Head Direction d4 e6 <class 'pynwb.behavior.SpatialSeries'>,  Head Direction d4 e7 <class 'pynwb.behavior.SpatialSeries'> }\n",
      "\n",
      "\n",
      "Speed <class 'pynwb.behavior.BehavioralTimeSeries'>\n",
      "Fields:\n",
      "  time_series: { Speed d4 e1 <class 'pynwb.base.TimeSeries'>,  Speed d4 e2 <class 'pynwb.base.TimeSeries'>,  Speed d4 e3 <class 'pynwb.base.TimeSeries'>,  Speed d4 e4 <class 'pynwb.base.TimeSeries'>,  Speed d4 e5 <class 'pynwb.base.TimeSeries'>,  Speed d4 e6 <class 'pynwb.base.TimeSeries'>,  Speed d4 e7 <class 'pynwb.base.TimeSeries'> }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "behavior_data = flh.parse_franklab_behavior_data(data_dir, animal, day)\n",
    "epoch_time_ivls = []\n",
    "time_idx, x_idx, y_idx, dir_idx, vel_idx = range(5)  # column ordering of the behavioral data matrix\n",
    "\n",
    "# Loop over each epoch of this day\n",
    "for epoch_num, epoch_data in behavior_data.items():\n",
    "\n",
    "    # Note that we convert timestamps to POSIX time\n",
    "    timestamps = epoch_data['data'][:,time_idx] + dataset_zero_time.timestamp()\n",
    "\n",
    "    # Store the times of epoch start and end. We will use these later to build the Epochs table\n",
    "    epoch_time_ivls.append([timestamps[0], timestamps[-1]])\n",
    "\n",
    "    # NWB expects meters per pixel\n",
    "    m_per_pixel = epoch_data['cmperpixel'][0,0]/100   \n",
    "\n",
    "    # Add this epoch's data to the PyNWB objects: position, head_dir, speed\n",
    "    position.create_spatial_series(name='Position d%d e%d' % (day, epoch_num), \n",
    "                                   timestamps=timestamps,\n",
    "                                   data=epoch_data['data'][:, (x_idx, y_idx)] * m_per_pixel,\n",
    "                                   reference_frame='corner of video frame')\n",
    "    head_dir.create_spatial_series(name='Head Direction d%d e%d'% (day, epoch_num), \n",
    "                                   timestamps=timestamps,\n",
    "                                   data=epoch_data['data'][:, dir_idx],\n",
    "                                   reference_frame='0=facing top of video frame (?), positive clockwise (?)')\n",
    "    speed.create_timeseries(name='Speed d%d e%d' % (day, epoch_num),\n",
    "                            timestamps=timestamps,\n",
    "                            data=epoch_data['data'][:, vel_idx] * m_per_pixel,\n",
    "                            unit='m/s',\n",
    "                            description='smoothed movement speed estimate')\n",
    "    \n",
    "print(\"Here are the same PyNWB objects, now filled with behavior data from each epoch:\")\n",
    "print(position)\n",
    "print(head_dir)\n",
    "print(speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the PyNWB behavior objects to the main NWBFile object\n",
    "Now that we have added the behavioral data to separate PyNWB objects (position, head_dir, speed), we need to put these objects into the appropriate place in the main PyNWB.NWBFile object. Specifically, we will add them to a [ProcessingModule](https://pynwb.readthedocs.io/en/latest/pynwb.base.html#pynwb.base.ProcessingModule), which is basically just a named bucket where we can store processed data of a particular type.  In our case, we will create a [ProcessingModule](https://pynwb.readthedocs.io/en/latest/pynwb.base.html#pynwb.base.ProcessingModule) called \"behavior\" for storing processed behavior data.\n",
    "\n",
    " We use the [add_data_interface](https://pynwb.readthedocs.io/en/latest/pynwb.core.html#pynwb.core.NWBDataInterface) method to add each of our behavior objects to the [ProcessingModule](https://pynwb.readthedocs.io/en/latest/pynwb.base.html#pynwb.base.ProcessingModule). The term \"data interface\" refers to an [NWBDataInterface](https://pynwb.readthedocs.io/en/latest/pynwb.core.html#pynwb.core.NWBDataInterface), which you might come across in reading the documentation. This terminology can be quite confusing, so we will reiterate what the terms mean:\n",
    "- a [ProcessingModule](https://pynwb.readthedocs.io/en/latest/pynwb.base.html#pynwb.base.ProcessingModule) is a named bucket where we put processed data of a particular type (e.g. behavior data)\n",
    "- an [NWBDataInterface](https://pynwb.readthedocs.io/en/latest/pynwb.core.html#pynwb.core.NWBDataInterface) is any datatype that we want to store in a [ProcessingModule](https://pynwb.readthedocs.io/en/latest/pynwb.base.html#pynwb.base.ProcessingModule). All of the datatypes that we used to store our behavior data are examples of this.\n",
    "\n",
    "One other thing to note here is the distinction between the PyNWB NWBFile object and the NWB file that we are creating. We have not yet saved anything to an NWB file on disk. We will do that at the end, after we have added everything to the PyNWB NWBFile object in the appropriate locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the ProcessingModule (i.e. bucket in the NWB file) where we will store all of the behavior data:\n",
      "\n",
      "Behavior <class 'pynwb.base.ProcessingModule'>\n",
      "Fields:\n",
      "  data_interfaces: { Head Direction <class 'pynwb.behavior.CompassDirection'>,  Position <class 'pynwb.behavior.Position'>,  Speed <class 'pynwb.behavior.BehavioralTimeSeries'> }\n",
      "  description: Behavioral data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a ProcessingModule for behavior data\n",
    "behav_mod = nwbf.create_processing_module(name='Behavior', \n",
    "                                          description='Behavioral data')\n",
    "\n",
    "# Add the position, head direction and speed data to the ProcessingModule\n",
    "behav_mod.add_data_interface(position)\n",
    "behav_mod.add_data_interface(head_dir)\n",
    "behav_mod.add_data_interface(speed)\n",
    "\n",
    "print(\"Here is the ProcessingModule (i.e. bucket in the NWB file) where we will store all of the behavior data:\")\n",
    "print(behav_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Represent behavioral tasks using Frank Lab NWB extension\n",
    "We represent each behavioral task as a Frank Lab Task (franklab.extensions.yaml). This object simply contains a name and a detailed description of the task. For the dataset here, we only have two tasks: W-Alternation and Sleep.\n",
    "\n",
    "We then store Task objects in the \"Behavior\" [ProcessingModule](https://pynwb.readthedocs.io/en/latest/pynwb.base.html#pynwb.base.ProcessingModule), just like we did with the other behavioral data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that we've added fl_extension.Task objects to our ProcessingModule:\n",
      "\n",
      "Behavior <class 'pynwb.base.ProcessingModule'>\n",
      "Fields:\n",
      "  data_interfaces: { Head Direction <class 'pynwb.behavior.CompassDirection'>,  Position <class 'pynwb.behavior.Position'>,  Sleep <class 'fl_extension.Task'>,  Speed <class 'pynwb.behavior.BehavioralTimeSeries'>,  W-Alternation <class 'fl_extension.Task'> }\n",
      "  description: Behavioral data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_name = 'Sleep'\n",
    "description = 'The animal sleeps or wanders freely around a small, empty box.'\n",
    "behav_mod.add_data_interface(fle.Task(name=task_name, description=description))\n",
    "\n",
    "task_name = 'W-Alternation'\n",
    "task_description = 'The animal runs in an alternating W pattern between three neighboring arms of a maze.'\n",
    "behav_mod.add_data_interface(fle.Task(name=task_name, description=task_description))\n",
    "\n",
    "print(\"Note that we've added fl_extension.Task objects to our ProcessingModule:\")\n",
    "print(behav_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Represent behavioral apparatuses using Frank Lab NWB extension\n",
    "Accurately representing the behavioral apparatuses (i.e. tracks, mazes, open fields, sleep boxes) is essential for interpreting the data. For the dataset here, we have three apparatuses: Sleep Box, W-track A, and W-track B. We represent each behavioral apparatus as a Frank Lab Apparatus (franklab.extensions.yaml), which uses a graph representation (i.e. nodes and edges) to represent the topology of a track.\n",
    "\n",
    "A Frank Lab Apparatus consists of a set of Nodes and Edges (i.e. it is a graph) describing the topology of the apparatus. Each Node represents an important component of the apparatus. For example:\n",
    "- PointNode represents 0D point with an x/y position (e.g. reward well, novel object)\n",
    "- SegmentNode represents a 1D line segment (e.g. linearized maze arm)\n",
    "- PolygonNode represents a 2D area (e.g. open field / non-linearizable area)\n",
    "\n",
    "Each Node object has a set of coordinates that describes its spatial geometry (e.g. the vertices for a PolygonNode). Nodes sharing at least one coordinate can be represented as spatially connected by adding an Edge. For example, we can represent a reward well (PointNode) at the end of a linearized W-track arm (SegmentNode) by adding an Edge connecting those nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the three Apparatus objects. Notice that they consist of 'edges' and 'nodes'.\n",
      "\n",
      "Sleep Box <class 'fl_extension.Apparatus'>\n",
      "Fields:\n",
      "  edges: { }\n",
      "  nodes: { Sleep box polygon <class 'fl_extension.PolygonNode'> }\n",
      "\n",
      "\n",
      "W-track A <class 'fl_extension.Apparatus'>\n",
      "Fields:\n",
      "  edges: { segment1<->segment2 <class 'fl_extension.Edge'>,  segment1<->segment4 <class 'fl_extension.Edge'>,  segment1<->well1 <class 'fl_extension.Edge'>,  segment2<->segment1 <class 'fl_extension.Edge'>,  segment2<->segment3 <class 'fl_extension.Edge'>,  segment2<->segment4 <class 'fl_extension.Edge'>,  segment3<->segment2 <class 'fl_extension.Edge'>,  segment3<->well2 <class 'fl_extension.Edge'>,  segment4<->segment1 <class 'fl_extension.Edge'>,  segment4<->segment2 <class 'fl_extension.Edge'>,  segment4<->segment5 <class 'fl_extension.Edge'>,  segment5<->segment4 <class 'fl_extension.Edge'>,  segment5<->well3 <class 'fl_extension.Edge'>,  well1<->segment1 <class 'fl_extension.Edge'>,  well2<->segment3 <class 'fl_extension.Edge'>,  well3<->segment5 <class 'fl_extension.Edge'> }\n",
      "  nodes: { segment1 <class 'fl_extension.SegmentNode'>,  segment2 <class 'fl_extension.SegmentNode'>,  segment3 <class 'fl_extension.SegmentNode'>,  segment4 <class 'fl_extension.SegmentNode'>,  segment5 <class 'fl_extension.SegmentNode'>,  well1 <class 'fl_extension.PointNode'>,  well2 <class 'fl_extension.PointNode'>,  well3 <class 'fl_extension.PointNode'> }\n",
      "\n",
      "\n",
      "W-track B <class 'fl_extension.Apparatus'>\n",
      "Fields:\n",
      "  edges: { segment1<->segment2 <class 'fl_extension.Edge'>,  segment1<->segment4 <class 'fl_extension.Edge'>,  segment1<->well1 <class 'fl_extension.Edge'>,  segment2<->segment1 <class 'fl_extension.Edge'>,  segment2<->segment3 <class 'fl_extension.Edge'>,  segment2<->segment4 <class 'fl_extension.Edge'>,  segment3<->segment2 <class 'fl_extension.Edge'>,  segment3<->well2 <class 'fl_extension.Edge'>,  segment4<->segment1 <class 'fl_extension.Edge'>,  segment4<->segment2 <class 'fl_extension.Edge'>,  segment4<->segment5 <class 'fl_extension.Edge'>,  segment5<->segment4 <class 'fl_extension.Edge'>,  segment5<->well3 <class 'fl_extension.Edge'>,  well1<->segment1 <class 'fl_extension.Edge'>,  well2<->segment3 <class 'fl_extension.Edge'>,  well3<->segment5 <class 'fl_extension.Edge'> }\n",
      "  nodes: { segment1 <class 'fl_extension.SegmentNode'>,  segment2 <class 'fl_extension.SegmentNode'>,  segment3 <class 'fl_extension.SegmentNode'>,  segment4 <class 'fl_extension.SegmentNode'>,  segment5 <class 'fl_extension.SegmentNode'>,  well1 <class 'fl_extension.PointNode'>,  well2 <class 'fl_extension.PointNode'>,  well3 <class 'fl_extension.PointNode'> }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------\n",
    "# Apparatus 1: Sleep Box\n",
    "#   The Sleep Box consists of a single PolygonNode representing the polygon area of the box.\n",
    "#   The vertices of this polygon are defined in the \"coords\" property of the PolygonNode.\n",
    "#   There are no edges since there is only one node.\n",
    "# ---------\n",
    "sleepbox_nodes = flh.get_sleepbox_nodes() \n",
    "sleepbox_edges = []  # Sleep box consists of only one Node, so it has no Edges by definition.\n",
    "sleep_box_apparatus = fle.Apparatus(name='Sleep Box', nodes=sleepbox_nodes, edges=sleepbox_edges)\n",
    "\n",
    "\n",
    "# ---------\n",
    "# Apparatus 2: W-track A\n",
    "#   This apparatus consists of several SegmentNodes representing the linearized segements of the W-track\n",
    "#   and three PointNodes representing the reward wells at the end of the three \"arms\" of the track.\n",
    "#   There are Edges connecting the SegmentNodes and PointNodes according to the topology of the\n",
    "#   track (i.e. edges connecting track components that are, in fact, connected spatially).\n",
    "# ---------\n",
    "wtrack_A_nodes = flh.get_wtrack_A_nodes()\n",
    "wtrack_A_edges = flh.find_edges(wtrack_A_nodes) # finds Nodes with 1 or more shared x/y coords\n",
    "wtrack_A_apparatus = fle.Apparatus(name='W-track A', nodes=wtrack_A_nodes, edges=wtrack_A_edges)\n",
    "\n",
    "\n",
    "# ---------\n",
    "# Apparatus 3: W-track B\n",
    "#   The second W-track used in this experiment has the same basic structure as W-track A, but\n",
    "#   its geometry is distinct and thus should be represented as a separate Apparatus object.\n",
    "# ---------\n",
    "wtrack_B_nodes = flh.get_wtrack_B_nodes()  \n",
    "wtrack_B_edges = flh.find_edges(wtrack_B_nodes)\n",
    "wtrack_B_apparatus = fle.Apparatus(name='W-track B', nodes=wtrack_B_nodes, edges=wtrack_B_edges)\n",
    "\n",
    "\n",
    "print(\"Here are the three Apparatus objects. Notice that they consist of 'edges' and 'nodes'.\")\n",
    "print(sleep_box_apparatus)\n",
    "print(wtrack_A_apparatus)\n",
    "print(wtrack_B_apparatus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the Apparatuses in the NWBFile object\n",
    "\n",
    "After building the Apparatus objects, we store them in the \"Behavior\" [ProcessingModule](https://pynwb.readthedocs.io/en/latest/pynwb.base.html#pynwb.base.ProcessingModule), just like we did with the other behavioral data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that our fl_extension.Apparatus objects are in the ProcessingModule:\n",
      "\n",
      "Behavior <class 'pynwb.base.ProcessingModule'>\n",
      "Fields:\n",
      "  data_interfaces: { Head Direction <class 'pynwb.behavior.CompassDirection'>,  Position <class 'pynwb.behavior.Position'>,  Sleep <class 'fl_extension.Task'>,  Sleep Box <class 'fl_extension.Apparatus'>,  Speed <class 'pynwb.behavior.BehavioralTimeSeries'>,  W-Alternation <class 'fl_extension.Task'>,  W-track A <class 'fl_extension.Apparatus'>,  W-track B <class 'fl_extension.Apparatus'> }\n",
      "  description: Behavioral data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------\n",
    "# Add all three Apparatuses to the \"Behavior\" ProcessingModule\n",
    "# ---------\n",
    "behav_mod.add_data_interface(sleep_box_apparatus)\n",
    "behav_mod.add_data_interface(wtrack_A_apparatus)\n",
    "behav_mod.add_data_interface(wtrack_B_apparatus)\n",
    "\n",
    "print(\"Note that our fl_extension.Apparatus objects are in the ProcessingModule:\")\n",
    "print(behav_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store epoch metadata in the NWBFile object\n",
    "We store metadata in the top-level [NWBFile.epochs](https://pynwb.readthedocs.io/en/latest/pynwb.file.html?highlight=epochs#pynwb.file.NWBFile.epochs) table. By default, there are required columns for 'start_time', 'stop_time', and 'tags'. We add additional metadata columns for the epoch's Task, Apparatus, etc. using the [NWBFile.add_epoch_column()](https://pynwb.readthedocs.io/en/latest/pynwb.file.html#pynwb.file.NWBFile.add_epoch_column) method. After we have all of the metadata columns set up, we add each epoch as a new row of the table using the [NWBFile.add_epoch()](https://pynwb.readthedocs.io/en/latest/pynwb.file.html#pynwb.file.NWBFile.add_epoch) method.\n",
    "\n",
    "<i>Take a look under the PyNWB hood</i>:</br>\n",
    "Each epoch occurs in a discrete time interval defined by its start and stop times. As such, the [NWBFile.epochs](https://pynwb.readthedocs.io/en/latest/pynwb.file.html?highlight=epochs#pynwb.file.NWBFile.epochs) table is an instance of [TimeIntervals](https://pynwb.readthedocs.io/en/latest/pynwb.epoch.html?highlight=TimeIntervals#pynwb.epoch.TimeIntervals), which is itself an instance of [DynamicTable](https://pynwb.readthedocs.io/en/latest/pynwb.core.html#pynwb.core.DynamicTable). Later, we will store electrodes and clustered units in two other DynamicTables. One of the advantages of using DynamicTables is it allows for adding arbitrary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an example epoch from the table. Note that the 'task' and 'apparatus' columns point to our Frank Lab extension objects.\n",
      "\n",
      "start_time                                          1.13641e+09\n",
      "stop_time                                           1.13641e+09\n",
      "exposure                                                     NA\n",
      "task          \\nSleep <class 'fl_extension.Task'>\\nFields:\\n...\n",
      "apparatus     \\nSleep Box <class 'fl_extension.Apparatus'>\\n...\n",
      "tags                                                         []\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ---------\n",
    "# Load epochs metadata from the Frank Lab Matlab files\n",
    "# ---------\n",
    "all_epochs_metadata = flh.parse_franklab_task_data(data_dir, animal, day)\n",
    "\n",
    "# ---------\n",
    "# Add metadata columns to the NWBFile.epochs table\n",
    "# By default, ithas columns for 'start_time', 'stop_time', and 'tags'.\n",
    "# ---------\n",
    "nwbf.add_epoch_column(name='exposure', description='number of exposures to this environment')\n",
    "nwbf.add_epoch_column(name='task', description='behavioral task for this epoch')\n",
    "nwbf.add_epoch_column(name='apparatus', description='behavioral apparatus for this epoch')\n",
    "\n",
    "# ---------\n",
    "# Iteratively add each epoch to the NWBFile.epochs table\n",
    "# ---------\n",
    "for epoch_num, epoch_metadata in all_epochs_metadata.items():\n",
    "    \n",
    "    # start and stop times were inferred from the behavior data earlier\n",
    "    epoch_start_time, epoch_stop_time = epoch_time_ivls[epoch_num-1]  \n",
    "    \n",
    "    # meter per pixel ratio is also in the behavior data\n",
    "    m_per_pixel = behavior_data[epoch_num]['cmperpixel'][0,0]/100  \n",
    "    \n",
    "    # Frank Lab Task (from the \"Behavior\" ProcessingModule)\n",
    "    epoch_task = flh.get_franklab_task(epoch_metadata, behav_mod)\n",
    "    \n",
    "    # Frank Lab Apparatus (from the \"Behavior\" ProcessingModule)\n",
    "    epoch_apparatus = flh.get_franklab_apparatus(epoch_metadata, behav_mod)\n",
    "    \n",
    "    epoch_exposure_num = flh.get_exposure_num(epoch_metadata)\n",
    "    \n",
    "    # Required column 'tags'. We do not presently use this.\n",
    "    epoch_tags = ''\n",
    "    \n",
    "    # Add this epoch to the NWBFile.epochs table\n",
    "    # Note that task and apparatus are soft links to the \"Behavior\" ProcessingModule, \n",
    "    # so they will not be unnecessarily duplicated within the NWBFile\n",
    "    nwbf.add_epoch(start_time=epoch_start_time,\n",
    "                   stop_time=epoch_stop_time,\n",
    "                   exposure=epoch_exposure_num,\n",
    "                   task=epoch_task,\n",
    "                   apparatus=epoch_apparatus,\n",
    "                   tags=epoch_tags)\n",
    "\n",
    "\n",
    "print(\"Here is an example epoch from the table.\\nNote that the 'task' and 'apparatus' columns point to our Frank Lab extension objects.\\n\")\n",
    "print(nwbf.epochs.to_dataframe().iloc[0, :])\n",
    "\n",
    "# print(\"Epoch number: {}\".format(nwbf.epochs[1][0] + 1))\n",
    "# print(\"Start, stop times: {0}, {1}\".format(nwbf.epochs[1][1], nwbf.epochs[1][2]))\n",
    "# print(\"Exposure number: {}\".format(nwbf.epochs[1][3]))\n",
    "# print(\"Task name: {}\".format(nwbf.epochs[1][4].name))\n",
    "# print(\"Apparatus name: {}\".format(nwbf.epochs[1][5].name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process tetrodes metadata\n",
    "\n",
    "1. Each tetrode gets an [ElectrodeGroup](https://pynwb.readthedocs.io/en/latest/pynwb.ecephys.html#pynwb.ecephys.ElectrodeGroup), where we store metadata about the tetrode such a unique name and the region of the brain it's in. \n",
    "\n",
    "2. Each individual recording channel (i.e. each of the 4 tetrode channels) gets its own row in the top-level [NWBFile.electrodes](https://pynwb.readthedocs.io/en/latest/pynwb.file.html?highlight=epochs#pynwb.file.NWBFile.electrodes) table. Here we store metadata about the electrode such as its location/depth in the brain, and the tetrode that it is part of.  We use the [NWBFile.add_electrode()](https://pynwb.readthedocs.io/en/latest/pynwb.file.html#pynwb.file.NWBFile.add_electrode) method to add each channel. As with the NWBFile.epochs table, discussed above, this is a DynamicTable.\n",
    "\n",
    "3. Each tetrode gets an \"Electrode Table Region\", an instance of [DynamicTableRegion](https://pynwb.readthedocs.io/en/latest/pynwb.core.html?highlight=DynamicTableRegion#pynwb.core.DynamicTableRegion). This is just a slice into the [NWBFile.electrodes](https://pynwb.readthedocs.io/en/latest/pynwb.file.html?highlight=epochs#pynwb.file.NWBFile.electrodes) table selecting the channels that go with the tetrode. We use the [create_electrode_table_region()]() method to add each tetrode's Electrode Table Region.\n",
    "\n",
    "4. Since LFP is often taken from a subset of a tetrode's channels, we create an Electrode Table Region for each tetrode's LFP channles. For example, if LFP was taken from just the first channel of a tetrode, we would create an Electrode Table Region just pointing to that channel of the [NWBFile.electrodes](https://pynwb.readthedocs.io/en/latest/pynwb.file.html?highlight=epochs#pynwb.file.NWBFile.electrodes) table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an example ElectrodeGroup for a tetrode: \n",
      "\n",
      "04-01 <class 'pynwb.ecephys.ElectrodeGroup'>\n",
      "Fields:\n",
      "  description: tetrode 1 located in CA3 on day 4\n",
      "  device: NSpike acquisition system <class 'pynwb.device.Device'>\n",
      "  location: CA3\n",
      "\n",
      "\n",
      "\n",
      "Here is the ElectrodeTableRegion for that tetrode:\n",
      "\n",
      "1 <class 'pynwb.core.DynamicTableRegion'>\n",
      "Fields:\n",
      "  description: tetrode 1 all channels\n",
      "  table: electrodes <class 'pynwb.core.DynamicTable'>\n",
      "\n",
      "\n",
      "\n",
      "Here is an example channel from the NWBFile.electrodes table:\n",
      "x                                                           NaN\n",
      "y                                                           NaN\n",
      "z                                                       3.94229\n",
      "imp                                                         NaN\n",
      "location                                                    CA3\n",
      "filtering                           unknown - likely 600Hz-6KHz\n",
      "group         \\n04-01 <class 'pynwb.ecephys.ElectrodeGroup'>...\n",
      "group_name                                                04-01\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Parse tetrodes metadata from the old Frank Lab Matlab files\n",
    "tetrode_metadata = flh.parse_franklab_tetrodes(data_dir, animal, day)\n",
    "\n",
    "# Represent our acquisition system with a 'Device' object\n",
    "recording_device = nwbf.create_device(name='NSpike acquisition system')\n",
    "\n",
    "# Four channels per tetrode by definition \n",
    "num_chan_per_tetrode = 4     \n",
    "\n",
    "# Initialize dictionaries to store the metadata\n",
    "tet_electrode_group = {}  # group for each tetrode\n",
    "tet_electrode_table_region = {}  # region for each tetrode (all channels)\n",
    "lfp_electrode_table_region = {}  # region for each tetrode's LFP channels\n",
    "\n",
    "chan_num = 0   # Incrementing channel number\n",
    "for tet_num, tet in tetrode_metadata.items():\n",
    "    \n",
    "    # Define some metadata parameters\n",
    "    tetrode_name = \"%02d-%02d\" % (day, tet_num) \n",
    "    impedance = np.nan\n",
    "    filtering = 'unknown - likely 600Hz-6KHz'\n",
    "    location = flh.get_franklab_tet_location(tet)  # area/subarea in the brain\n",
    "    coord = flh.get_franklab_tet_coord(tet)  # x/y/z coordinate in the brain\n",
    "    description = \"tetrode {tet_num} located in {location} on day {day}\".format(\n",
    "        tet_num=tet_num, location=location, day=day)\n",
    "    \n",
    "    # 1. Represent the tetrode in NWB as an ElectrodeGroup\n",
    "    tet_electrode_group[tet_num] = nwbf.create_electrode_group(name=tetrode_name,\n",
    "                                                               description=description,\n",
    "                                                               location=location,\n",
    "                                                               device=recording_device)\n",
    "    \n",
    "    # 2. Represent each channels of the tetrode as a row in the NWBFile.electrodes table.\n",
    "    for i in range(num_chan_per_tetrode):\n",
    "            nwbf.add_electrode(x=coord[0],\n",
    "                               y=coord[1],\n",
    "                               z=coord[2],\n",
    "                               imp=impedance,\n",
    "                               location=location,\n",
    "                               filtering=filtering,\n",
    "                               group=tet_electrode_group[tet_num],  # tetrode this electrode belongs to\n",
    "                               group_name=tet_electrode_group[tet_num].name,\n",
    "                               id=chan_num)\n",
    "            chan_num = chan_num + 1  # total number of channels processed so far across all tets\n",
    "            \n",
    "    # 3. Create an Electrode Table Region (slice into the electrodes table) for each tetrode\n",
    "    table_region_description = 'tetrode %d all channels' % tet_num\n",
    "    table_region_name = '%d' % tet_num\n",
    "    table_region_rows = list(range(chan_num - num_chan_per_tetrode, chan_num)) # rows of NWBFile.electrodes table\n",
    "    tet_electrode_table_region[tet_num] = nwbf.create_electrode_table_region(\n",
    "        region=table_region_rows,\n",
    "        description=table_region_description,\n",
    "        name=table_region_name)\n",
    "\n",
    "    # 4. Create an ElectrodeTableRegion for each tetrode's LFP recordings\n",
    "    lfp_channels = [chan_num - num_chan_per_tetrode] # Assume that LFP is taken from the first channel\n",
    "    table_region_description = 'tetrode %d LFP channels' % tet_num\n",
    "    lfp_electrode_table_region[tet_num] = nwbf.create_electrode_table_region(\n",
    "        region=lfp_channels,\n",
    "        description=table_region_description,\n",
    "        name=table_region_name)\n",
    "\n",
    "print(\"Here is an example ElectrodeGroup for a tetrode: \")\n",
    "print(tet_electrode_group[1])\n",
    "print('\\n')\n",
    "print(\"Here is the ElectrodeTableRegion for that tetrode:\")\n",
    "print(tet_electrode_table_region[1])\n",
    "print('\\n')\n",
    "print(\"Here is an example channel from the NWBFile.electrodes table:\")\n",
    "print(nwbf.electrodes.to_dataframe().iloc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the EEG data sub-directory\n",
    "eeg_subdir = \"EEG\"\n",
    "eeg_path = os.path.join(data_dir, eeg_subdir)\n",
    "if not os.path.exists(eeg_path):\n",
    "    raise new RuntimeException('Error: eeg_path %s does not exist' % eeg_path)\n",
    "    \n",
    "day_str = '%02d' % day \n",
    "nwb_filename = anim + day_str + '.nwb'\n",
    "\n",
    "prefix = anim.lower()\n",
    "\n",
    "eeg_subdir = \"EEG\"\n",
    "eeg_path = os.path.join(data_dir, eeg_subdir)\n",
    "\n",
    "# Specific file names\n",
    "epochs_file = \"times.mat\"\n",
    "tetinfo_file = \"tetinfo.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
